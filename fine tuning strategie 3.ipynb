{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "#from scipy.misc import imresize, imread\n",
    "import itertools\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, learning_curve, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPool2D, MaxPooling2D\n",
    "%matplotlib inline\n",
    "# charger des images formes (5547, 50, 50, 3)\n",
    "X = np.load('D:/test cancer rbreast/crop/zoom_100m.npy')  \n",
    "\n",
    "# charger des images  (5547,1); (0 = no cancer, 1 = cancer)\n",
    "Y = np.load('D:/test cancer rbreast/crop/zoom_100m_label.npy')   \n",
    "perm_array = np.arange(len(X))\n",
    "#arrange genere tous toute les val jusqua la longuer de x_images\n",
    "np.random.shuffle(perm_array)\n",
    "#il melange les images\n",
    "X = X[perm_array]\n",
    "Y = Y[perm_array]\n",
    "#en split notre dataset 80 % 20 %\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "# en redduit la taille de l'echantillon au cas ou en avais trop d'images \n",
    "#pour pas que ca prend trop de temps pour le pc \n",
    "#mais ici c'est pas le cas donc en commente ce code\n",
    "#X_train = X_train[0:30000] \n",
    "#Y_train = Y_train[0:30000]\n",
    "#X_test = X_test[0:30000] \n",
    "#Y_test = Y_test[0:30000]\n",
    "# normalizer nos donnees \n",
    "#en pourrais utiliser d'autre methodes aussi mais celle la c'est bien \n",
    "X_train = X_train / 256.0\n",
    "X_test = X_test / 256.0\n",
    "#methode qu'on a trouver sur internet et qu'on a utiliser \n",
    "X_trainShape = X_train.shape[1]*X_train.shape[2]*X_train.shape[3]\n",
    "X_testShape = X_test.shape[1]*X_test.shape[2]*X_test.shape[3]\n",
    "#en applatit les donnees en gros en les transfrome en une matrice 1 seul dimmenssion nbr elem*(width*height*channel)\n",
    "X_trainFlat = X_train.reshape(X_train.shape[0], X_trainShape)\n",
    "X_testFlat = X_test.reshape(X_test.shape[0], X_testShape)\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    en va plot un learning curve grace au code de ce lien http://scikit-learn.org/stable/modules/learning_curve.html\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"exemples de test\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"score d'entrainement\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"score du cross validation\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "def plotLotsOfLearningCurves(a,b):\n",
    "    \"\"\" en va plot bcp de learning curve http://scikit-learn.org/stable/modules/learning_curve.html\"\"\"\n",
    "    models = []\n",
    "    models.append(('Support Vector Machine', SVC()))\n",
    "    for name, model in models:\n",
    "        plot_learning_curve(model, 'Learning Curve For %s Classifier'% (name), a,b, (0.5,1), 10)\n",
    "#plotLotsOfLearningCurves(X_trainFlat, Y_train)\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='matrice d econfusion',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    en affiche la matrice de confusion\n",
    "    en peut normalizer les donnees en metant normalize a true\n",
    "    \"\"\"\n",
    "    plt.figure(figsize = (5,5))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "#Run SVC w/ Confusion Matrix\n",
    "def runSVCconfusion(a,b,c,d):\n",
    "    \"\"\"methodes qui affiches les matrices de confusiondu model svc (comme exmeple) en normalizer et non normalizer\"\"\"\n",
    "    model = SVC()\n",
    "    model.fit(a, b)\n",
    "    prediction = model.predict(c)\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    accuracy = model_selection.cross_val_score(model, c,d, cv=kfold, scoring='accuracy')\n",
    "    mean = accuracy.mean() \n",
    "    stdev = accuracy.std()\n",
    "    print('\\nSupport Vector Machine - Training set accuracy: %s (%s)' % (mean, stdev),\"\\n\")\n",
    "    cnf_matrix = confusion_matrix(d, prediction)\n",
    "    np.set_printoptions(precision=2)\n",
    "    class_names = [\"diagnostic\" \"IDC(-)\", \"diagnostic\" \"IDC(+)\"]\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                          title='Confusion matrix, sans la normalization')\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                          title=' confusion matrix avec normalization')\n",
    "    plt.show()\n",
    "#runSVCconfusion(X_trainFlat, Y_train, X_testFlat, Y_test)\n",
    "Y_train = to_categorical(Y_train, num_classes = 2)\n",
    "Y_test = to_categorical(Y_test, num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1030 samples, validate on 258 samples\n",
      "Epoch 1/100\n",
      "1030/1030 [==============================] - 7s 7ms/step - loss: 0.5097 - acc: 0.8883 - val_loss: 0.4240 - val_acc: 0.8798\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.87984, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop.hdf5\n",
      "Epoch 2/100\n",
      " 640/1030 [=================>............] - ETA: 4s - loss: 0.3198 - acc: 0.9047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nazim\\Anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.105465). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 8s 7ms/step - loss: 0.2856 - acc: 0.9078 - val_loss: 0.2606 - val_acc: 0.8760\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.87984\n",
      "Epoch 3/100\n",
      "1030/1030 [==============================] - 0s 454us/step - loss: 0.1849 - acc: 0.9233 - val_loss: 0.2604 - val_acc: 0.8798\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.87984\n",
      "Epoch 4/100\n",
      "1030/1030 [==============================] - 0s 452us/step - loss: 0.1909 - acc: 0.9252 - val_loss: 0.2579 - val_acc: 0.8837\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.87984 to 0.88372, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop.hdf5\n",
      "Epoch 5/100\n",
      "1030/1030 [==============================] - 0s 455us/step - loss: 0.1769 - acc: 0.9233 - val_loss: 0.2592 - val_acc: 0.8876\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.88372 to 0.88760, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop.hdf5\n",
      "Epoch 6/100\n",
      "1030/1030 [==============================] - 0s 471us/step - loss: 0.1411 - acc: 0.9437 - val_loss: 0.2166 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.88760 to 0.90310, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop.hdf5\n",
      "Epoch 7/100\n",
      "1030/1030 [==============================] - 0s 476us/step - loss: 0.1473 - acc: 0.9340 - val_loss: 0.2339 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.90310\n",
      "Epoch 8/100\n",
      "1030/1030 [==============================] - 0s 440us/step - loss: 0.1189 - acc: 0.9505 - val_loss: 0.2199 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.90310\n",
      "Epoch 9/100\n",
      "1030/1030 [==============================] - 0s 437us/step - loss: 0.1127 - acc: 0.9495 - val_loss: 0.2362 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.90310\n",
      "Epoch 10/100\n",
      "1030/1030 [==============================] - 0s 440us/step - loss: 0.1257 - acc: 0.9495 - val_loss: 0.3089 - val_acc: 0.8798\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.90310\n",
      "Epoch 11/100\n",
      "1030/1030 [==============================] - 0s 452us/step - loss: 0.1173 - acc: 0.9524 - val_loss: 0.2373 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.90310 to 0.90698, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop.hdf5\n",
      "Epoch 12/100\n",
      "1030/1030 [==============================] - 0s 443us/step - loss: 0.1149 - acc: 0.9583 - val_loss: 0.2765 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.90698\n",
      "Epoch 13/100\n",
      "1030/1030 [==============================] - 0s 435us/step - loss: 0.0900 - acc: 0.9670 - val_loss: 0.2336 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.90698 to 0.91473, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop.hdf5\n",
      "Epoch 14/100\n",
      "1030/1030 [==============================] - 0s 439us/step - loss: 0.0948 - acc: 0.9553 - val_loss: 0.2753 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.91473\n",
      "Epoch 15/100\n",
      "1030/1030 [==============================] - 0s 437us/step - loss: 0.0837 - acc: 0.9660 - val_loss: 0.2216 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.91473\n",
      "Epoch 16/100\n",
      "1030/1030 [==============================] - 0s 443us/step - loss: 0.0954 - acc: 0.9641 - val_loss: 0.2157 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.91473 to 0.93411, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop.hdf5\n",
      "Epoch 17/100\n",
      "1030/1030 [==============================] - 0s 445us/step - loss: 0.1052 - acc: 0.9573 - val_loss: 0.2265 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.93411\n",
      "Epoch 18/100\n",
      "1030/1030 [==============================] - 0s 441us/step - loss: 0.1062 - acc: 0.9631 - val_loss: 0.2098 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.93411\n",
      "Epoch 19/100\n",
      "1030/1030 [==============================] - 0s 438us/step - loss: 0.0663 - acc: 0.9777 - val_loss: 0.2210 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.93411\n",
      "Epoch 20/100\n",
      "1030/1030 [==============================] - 0s 442us/step - loss: 0.0655 - acc: 0.9777 - val_loss: 0.2274 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.93411\n",
      "Epoch 21/100\n",
      "1030/1030 [==============================] - 0s 437us/step - loss: 0.0582 - acc: 0.9757 - val_loss: 0.2523 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.93411\n",
      "Epoch 22/100\n",
      "1030/1030 [==============================] - 0s 448us/step - loss: 0.0771 - acc: 0.9670 - val_loss: 0.2952 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.93411\n",
      "Epoch 23/100\n",
      "1030/1030 [==============================] - 0s 442us/step - loss: 0.0694 - acc: 0.9767 - val_loss: 0.2068 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.93411\n",
      "Epoch 24/100\n",
      "1030/1030 [==============================] - 0s 438us/step - loss: 0.0812 - acc: 0.9680 - val_loss: 0.2425 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.93411\n",
      "Epoch 25/100\n",
      "1030/1030 [==============================] - 0s 438us/step - loss: 0.0467 - acc: 0.9825 - val_loss: 0.2476 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.93411\n",
      "Epoch 26/100\n",
      "1030/1030 [==============================] - 0s 436us/step - loss: 0.0590 - acc: 0.9835 - val_loss: 0.2365 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.93411\n",
      "Epoch 27/100\n",
      "1030/1030 [==============================] - 0s 438us/step - loss: 0.0542 - acc: 0.9757 - val_loss: 0.2760 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.93411\n",
      "Epoch 28/100\n",
      "1030/1030 [==============================] - 0s 438us/step - loss: 0.0552 - acc: 0.9835 - val_loss: 0.3509 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.93411\n",
      "Epoch 29/100\n",
      "1030/1030 [==============================] - 0s 437us/step - loss: 0.0486 - acc: 0.9786 - val_loss: 0.2583 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.93411\n",
      "Epoch 30/100\n",
      "1030/1030 [==============================] - 0s 438us/step - loss: 0.0455 - acc: 0.9786 - val_loss: 0.3022 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.93411\n",
      "Epoch 31/100\n",
      "1030/1030 [==============================] - 0s 437us/step - loss: 0.0478 - acc: 0.9816 - val_loss: 0.3062 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.93411\n",
      "Epoch 32/100\n",
      "1030/1030 [==============================] - 0s 435us/step - loss: 0.0333 - acc: 0.9874 - val_loss: 0.2995 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.93411\n",
      "Epoch 33/100\n",
      "1030/1030 [==============================] - 0s 438us/step - loss: 0.0563 - acc: 0.9825 - val_loss: 0.2883 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.93411\n",
      "Epoch 34/100\n",
      "1030/1030 [==============================] - 0s 438us/step - loss: 0.0475 - acc: 0.9854 - val_loss: 0.3375 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.93411\n",
      "Epoch 35/100\n",
      "1030/1030 [==============================] - 0s 438us/step - loss: 0.0552 - acc: 0.9816 - val_loss: 0.2776 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.93411\n",
      "Epoch 36/100\n",
      "1030/1030 [==============================] - 0s 442us/step - loss: 0.0522 - acc: 0.9845 - val_loss: 0.3518 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.93411\n",
      "Epoch 37/100\n",
      "1030/1030 [==============================] - 0s 437us/step - loss: 0.0513 - acc: 0.9825 - val_loss: 0.2985 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.93411\n",
      "Epoch 38/100\n",
      "1030/1030 [==============================] - 0s 440us/step - loss: 0.0435 - acc: 0.9845 - val_loss: 0.3136 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.93411\n",
      "Epoch 39/100\n",
      "1030/1030 [==============================] - 0s 439us/step - loss: 0.0398 - acc: 0.9864 - val_loss: 0.2803 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.93411\n",
      "Epoch 40/100\n",
      "1030/1030 [==============================] - 0s 437us/step - loss: 0.0336 - acc: 0.9883 - val_loss: 0.3570 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.93411\n",
      "Epoch 41/100\n",
      "1030/1030 [==============================] - 0s 434us/step - loss: 0.0414 - acc: 0.9835 - val_loss: 0.2863 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.93411\n",
      "Epoch 42/100\n",
      "1030/1030 [==============================] - 0s 437us/step - loss: 0.0226 - acc: 0.9913 - val_loss: 0.3053 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.93411\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 0s 441us/step - loss: 0.0110 - acc: 0.9971 - val_loss: 0.3146 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.93411\n",
      "Epoch 44/100\n",
      "1030/1030 [==============================] - 0s 437us/step - loss: 0.0418 - acc: 0.9922 - val_loss: 0.2979 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.93411\n",
      "Epoch 45/100\n",
      "1030/1030 [==============================] - 0s 438us/step - loss: 0.0243 - acc: 0.9922 - val_loss: 0.2960 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.93411\n",
      "Epoch 46/100\n",
      "1030/1030 [==============================] - 0s 436us/step - loss: 0.0346 - acc: 0.9874 - val_loss: 0.3289 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.93411\n",
      "Epoch 47/100\n",
      "1030/1030 [==============================] - 0s 437us/step - loss: 0.0374 - acc: 0.9893 - val_loss: 0.3385 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.93411\n",
      "Epoch 48/100\n",
      "1030/1030 [==============================] - 0s 439us/step - loss: 0.0269 - acc: 0.9932 - val_loss: 0.3405 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.93411\n",
      "Epoch 49/100\n",
      "1030/1030 [==============================] - 0s 441us/step - loss: 0.0310 - acc: 0.9893 - val_loss: 0.3452 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.93411\n",
      "Epoch 50/100\n",
      "1030/1030 [==============================] - 0s 436us/step - loss: 0.0385 - acc: 0.9864 - val_loss: 0.4228 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.93411\n",
      "Epoch 51/100\n",
      "1030/1030 [==============================] - 0s 434us/step - loss: 0.0368 - acc: 0.9874 - val_loss: 0.3753 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.93411\n",
      "Epoch 52/100\n",
      "1030/1030 [==============================] - 0s 456us/step - loss: 0.0487 - acc: 0.9883 - val_loss: 0.3152 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.93411\n",
      "Epoch 53/100\n",
      "1030/1030 [==============================] - 0s 440us/step - loss: 0.0223 - acc: 0.9903 - val_loss: 0.3407 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.93411\n",
      "Epoch 54/100\n",
      "1030/1030 [==============================] - 0s 438us/step - loss: 0.0191 - acc: 0.9932 - val_loss: 0.3940 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.93411\n",
      "Epoch 55/100\n",
      "1030/1030 [==============================] - 0s 438us/step - loss: 0.0162 - acc: 0.9951 - val_loss: 0.3808 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.93411\n",
      "Epoch 56/100\n",
      "1030/1030 [==============================] - 0s 439us/step - loss: 0.0237 - acc: 0.9903 - val_loss: 0.3616 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.93411\n",
      "Epoch 57/100\n",
      "1030/1030 [==============================] - 0s 442us/step - loss: 0.0404 - acc: 0.9864 - val_loss: 0.3576 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.93411\n",
      "Epoch 58/100\n",
      "1030/1030 [==============================] - 0s 447us/step - loss: 0.0267 - acc: 0.9913 - val_loss: 0.3813 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.93411\n",
      "Epoch 59/100\n",
      "1030/1030 [==============================] - 0s 439us/step - loss: 0.0177 - acc: 0.9951 - val_loss: 0.4035 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.93411\n",
      "Epoch 60/100\n",
      "1030/1030 [==============================] - 0s 438us/step - loss: 0.0223 - acc: 0.9903 - val_loss: 0.2952 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.93411\n",
      "Epoch 61/100\n",
      "1030/1030 [==============================] - 0s 433us/step - loss: 0.0215 - acc: 0.9893 - val_loss: 0.3055 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.93411\n",
      "Epoch 62/100\n",
      "1030/1030 [==============================] - 0s 443us/step - loss: 0.0238 - acc: 0.9932 - val_loss: 0.3477 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.93411\n",
      "Epoch 63/100\n",
      "1030/1030 [==============================] - 0s 442us/step - loss: 0.0391 - acc: 0.9913 - val_loss: 0.3020 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.93411\n",
      "Epoch 64/100\n",
      "1030/1030 [==============================] - 0s 436us/step - loss: 0.0283 - acc: 0.9913 - val_loss: 0.3598 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.93411\n",
      "Epoch 65/100\n",
      "1030/1030 [==============================] - 0s 437us/step - loss: 0.0168 - acc: 0.9942 - val_loss: 0.3939 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.93411\n",
      "Epoch 66/100\n",
      "1030/1030 [==============================] - 0s 438us/step - loss: 0.0217 - acc: 0.9903 - val_loss: 0.4286 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.93411\n",
      "Epoch 67/100\n",
      "1030/1030 [==============================] - 0s 438us/step - loss: 0.0274 - acc: 0.9883 - val_loss: 0.3469 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.93411\n",
      "Epoch 68/100\n",
      "1030/1030 [==============================] - 0s 439us/step - loss: 0.0140 - acc: 0.9981 - val_loss: 0.4058 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.93411\n",
      "Epoch 69/100\n",
      "1030/1030 [==============================] - 0s 438us/step - loss: 0.0257 - acc: 0.9942 - val_loss: 0.3904 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.93411\n",
      "Epoch 70/100\n",
      "1030/1030 [==============================] - 0s 437us/step - loss: 0.0237 - acc: 0.9903 - val_loss: 0.4293 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.93411\n",
      "Epoch 71/100\n",
      "1030/1030 [==============================] - 0s 438us/step - loss: 0.0251 - acc: 0.9971 - val_loss: 0.3553 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.93411\n",
      "Epoch 72/100\n",
      "1030/1030 [==============================] - 0s 439us/step - loss: 0.0165 - acc: 0.9961 - val_loss: 0.3273 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.93411\n",
      "Epoch 73/100\n",
      "1030/1030 [==============================] - 0s 438us/step - loss: 0.0229 - acc: 0.9932 - val_loss: 0.4210 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.93411\n",
      "Epoch 74/100\n",
      "1030/1030 [==============================] - 0s 436us/step - loss: 0.0200 - acc: 0.9883 - val_loss: 0.3935 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.93411\n",
      "Epoch 75/100\n",
      "1030/1030 [==============================] - 0s 436us/step - loss: 0.0212 - acc: 0.9922 - val_loss: 0.3598 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.93411\n",
      "Epoch 76/100\n",
      "1030/1030 [==============================] - 0s 439us/step - loss: 0.0169 - acc: 0.9932 - val_loss: 0.3326 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.93411\n",
      "Epoch 77/100\n",
      "1030/1030 [==============================] - 0s 436us/step - loss: 0.0275 - acc: 0.9903 - val_loss: 0.3495 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.93411\n",
      "Epoch 78/100\n",
      "1030/1030 [==============================] - 0s 436us/step - loss: 0.0205 - acc: 0.9932 - val_loss: 0.4371 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.93411\n",
      "Epoch 79/100\n",
      "1030/1030 [==============================] - 0s 438us/step - loss: 0.0352 - acc: 0.9854 - val_loss: 0.3990 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.93411\n",
      "Epoch 80/100\n",
      "1030/1030 [==============================] - 0s 438us/step - loss: 0.0137 - acc: 0.9942 - val_loss: 0.3880 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.93411\n",
      "Epoch 81/100\n",
      "1030/1030 [==============================] - 0s 441us/step - loss: 0.0131 - acc: 0.9971 - val_loss: 0.3402 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.93411\n",
      "Epoch 82/100\n",
      "1030/1030 [==============================] - 0s 437us/step - loss: 0.0077 - acc: 0.9971 - val_loss: 0.3997 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.93411\n",
      "Epoch 83/100\n",
      "1030/1030 [==============================] - 0s 442us/step - loss: 0.0054 - acc: 0.9990 - val_loss: 0.3978 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.93411\n",
      "Epoch 84/100\n",
      "1030/1030 [==============================] - 0s 436us/step - loss: 0.0155 - acc: 0.9951 - val_loss: 0.3433 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.93411\n",
      "Epoch 85/100\n",
      "1030/1030 [==============================] - 0s 468us/step - loss: 0.0098 - acc: 0.9961 - val_loss: 0.4037 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.93411\n",
      "Epoch 86/100\n",
      "1030/1030 [==============================] - 0s 466us/step - loss: 0.0156 - acc: 0.9942 - val_loss: 0.4266 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.93411\n",
      "Epoch 87/100\n",
      "1030/1030 [==============================] - 0s 453us/step - loss: 0.0142 - acc: 0.9961 - val_loss: 0.3761 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.93411\n",
      "Epoch 88/100\n",
      "1030/1030 [==============================] - 0s 448us/step - loss: 0.0178 - acc: 0.9942 - val_loss: 0.5283 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.93411\n",
      "Epoch 89/100\n",
      "1030/1030 [==============================] - 0s 476us/step - loss: 0.0210 - acc: 0.9913 - val_loss: 0.4884 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.93411\n",
      "Epoch 90/100\n",
      "1030/1030 [==============================] - 0s 463us/step - loss: 0.0096 - acc: 0.9961 - val_loss: 0.4726 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.93411\n",
      "Epoch 91/100\n",
      "1030/1030 [==============================] - 0s 460us/step - loss: 0.0077 - acc: 0.9990 - val_loss: 0.4859 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.93411\n",
      "Epoch 92/100\n",
      "1030/1030 [==============================] - 0s 469us/step - loss: 0.0054 - acc: 0.9990 - val_loss: 0.4693 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.93411\n",
      "Epoch 93/100\n",
      "1030/1030 [==============================] - 0s 451us/step - loss: 0.0095 - acc: 0.9971 - val_loss: 0.4274 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.93411\n",
      "Epoch 94/100\n",
      "1030/1030 [==============================] - 0s 450us/step - loss: 0.0060 - acc: 0.9981 - val_loss: 0.4704 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.93411\n",
      "Epoch 95/100\n",
      "1030/1030 [==============================] - 0s 446us/step - loss: 0.0087 - acc: 0.9961 - val_loss: 0.5207 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.93411\n",
      "Epoch 96/100\n",
      "1030/1030 [==============================] - 0s 449us/step - loss: 0.0230 - acc: 0.9932 - val_loss: 0.3659 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.93411\n",
      "Epoch 97/100\n",
      "1030/1030 [==============================] - 0s 443us/step - loss: 0.0587 - acc: 0.9883 - val_loss: 0.4029 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.93411\n",
      "Epoch 98/100\n",
      "1030/1030 [==============================] - 0s 445us/step - loss: 0.0244 - acc: 0.9913 - val_loss: 0.4113 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.93411\n",
      "Epoch 99/100\n",
      "1030/1030 [==============================] - 0s 448us/step - loss: 0.0113 - acc: 0.9961 - val_loss: 0.4138 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.93411\n",
      "Epoch 100/100\n",
      "1030/1030 [==============================] - 0s 450us/step - loss: 0.0133 - acc: 0.9951 - val_loss: 0.4499 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.93411\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 50, 50, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 50, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 25, 25, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 86)        49622     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 86)        66650     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 86)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 6, 86)          344       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 86)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              3171328   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 3,879,722\n",
      "Trainable params: 3,697,326\n",
      "Non-trainable params: 182,396\n",
      "_________________________________________________________________\n",
      "\n",
      "Keras CNN 1 - accuracy: 0.8992248062015504 \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      IDC(-)       0.89      0.93      0.91       143\n",
      "      IDC(+)       0.91      0.86      0.88       115\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       258\n",
      "   macro avg       0.90      0.90      0.90       258\n",
      "weighted avg       0.90      0.90      0.90       258\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "class MetricsCheckpoint(Callback):\n",
    "    \"\"\"apres chaque epoch en sauvegarde metrics\"\"\"\n",
    "    def __init__(self, savepath):\n",
    "        #constructeur de la class\n",
    "        super(MetricsCheckpoint, self).__init__()\n",
    "        self.savepath = savepath\n",
    "        self.history = {}\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        np.save(self.savepath, self.history)\n",
    "\n",
    "def plotKerasLearningCurve():\n",
    "    #en affiche juste la courbe de notre model\n",
    "    plt.figure(figsize=(10,5))\n",
    "    metrics = np.load('logs.npy')[()]\n",
    "    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n",
    "    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n",
    "        l = np.array(metrics[k])\n",
    "        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n",
    "        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n",
    "        y = l[x]\n",
    "        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n",
    "        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n",
    "    plt.legend(loc=4)\n",
    "    plt.axis([0, None, None, None]);\n",
    "    plt.grid()\n",
    "    plt.xlabel('nombre d epoques')\n",
    "def runKerasCNN(a,b,c,d):\n",
    "    \"\"\"\n",
    "    en a utiliser ce lien\n",
    "    https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n",
    "    en a utilise run model qui marche bien sur MNIST sur notre dataset\n",
    "    \"\"\"\n",
    "    batch_size = 128\n",
    "    num_classes = 2\n",
    "    epochs = 5\n",
    "    img_rows, img_cols = X_train.shape[1],X_train.shape[2]\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "    x_train = a\n",
    "    y_train = b\n",
    "    x_test = c\n",
    "    y_test = d   \n",
    "    model = Sequential()\n",
    "    #test d'un premier model\n",
    "    #test d'un premier model\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu', input_shape = input_shape))\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation = \"softmax\"))\n",
    "    # load weights\n",
    "    model.load_weights(\"weights.traint_40zoom_modelcomplex_avec_crop.hdf5\")\n",
    "    for layer in model.layers[:12]:\n",
    "        layer.trainable = False\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    filepath=\"weights.traint_40_100_zoom_modelcomplex_avec_crop.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    history =model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              verbose=1,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),callbacks=callbacks_list)\n",
    "    model.summary()\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('\\nKeras CNN 1 - accuracy:', score[1],'\\n')\n",
    "    y_pred = model.predict(c) \n",
    "    map_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\n",
    "    print('\\n', sklearn.metrics.classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='')\n",
    "    Y_pred_classes = np.argmax(y_pred,axis = 1) \n",
    "    Y_true = np.argmax(Y_test,axis = 1) \n",
    "    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "    plot_confusion_matrix(confusion_mtx, classes = list(map_characters.values()))\n",
    "     \n",
    "runKerasCNN(X_train, Y_train,  X_test, Y_test)\n",
    "#plotKerasLearningCurve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1030 samples, validate on 258 samples\n",
      "Epoch 1/100\n",
      "1030/1030 [==============================] - 1s 957us/step - loss: 0.7595 - acc: 0.8825 - val_loss: 0.5043 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89147, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop2.hdf5\n",
      "Epoch 2/100\n",
      "1030/1030 [==============================] - 0s 362us/step - loss: 0.6136 - acc: 0.8816 - val_loss: 0.4301 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.89147\n",
      "Epoch 3/100\n",
      "1030/1030 [==============================] - 0s 422us/step - loss: 0.5186 - acc: 0.8845 - val_loss: 0.3814 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.89147\n",
      "Epoch 4/100\n",
      "1030/1030 [==============================] - 0s 415us/step - loss: 0.4442 - acc: 0.8942 - val_loss: 0.3459 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.89147 to 0.89535, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop2.hdf5\n",
      "Epoch 5/100\n",
      "1030/1030 [==============================] - 0s 374us/step - loss: 0.3275 - acc: 0.8922 - val_loss: 0.3206 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89535\n",
      "Epoch 6/100\n",
      "1030/1030 [==============================] - 0s 359us/step - loss: 0.3300 - acc: 0.8864 - val_loss: 0.2930 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.89535 to 0.89922, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop2.hdf5\n",
      "Epoch 7/100\n",
      "1030/1030 [==============================] - 0s 359us/step - loss: 0.3088 - acc: 0.8932 - val_loss: 0.2787 - val_acc: 0.8837\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.89922\n",
      "Epoch 8/100\n",
      "1030/1030 [==============================] - 0s 354us/step - loss: 0.3163 - acc: 0.8748 - val_loss: 0.2832 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.89922\n",
      "Epoch 9/100\n",
      "1030/1030 [==============================] - 0s 357us/step - loss: 0.2784 - acc: 0.8874 - val_loss: 0.2756 - val_acc: 0.8837\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.89922\n",
      "Epoch 10/100\n",
      "1030/1030 [==============================] - 0s 354us/step - loss: 0.2737 - acc: 0.9010 - val_loss: 0.2745 - val_acc: 0.8876\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.89922\n",
      "Epoch 11/100\n",
      "1030/1030 [==============================] - 0s 354us/step - loss: 0.3049 - acc: 0.8961 - val_loss: 0.2644 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.89922 to 0.90310, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop2.hdf5\n",
      "Epoch 12/100\n",
      "1030/1030 [==============================] - 0s 351us/step - loss: 0.2893 - acc: 0.8786 - val_loss: 0.2697 - val_acc: 0.8837\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.90310\n",
      "Epoch 13/100\n",
      "1030/1030 [==============================] - 0s 347us/step - loss: 0.2487 - acc: 0.8903 - val_loss: 0.2718 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.90310\n",
      "Epoch 14/100\n",
      "1030/1030 [==============================] - ETA: 0s - loss: 0.2623 - acc: 0.891 - 0s 350us/step - loss: 0.2691 - acc: 0.8913 - val_loss: 0.2722 - val_acc: 0.8876\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.90310\n",
      "Epoch 15/100\n",
      "1030/1030 [==============================] - 0s 347us/step - loss: 0.2652 - acc: 0.8913 - val_loss: 0.2702 - val_acc: 0.8837\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.90310\n",
      "Epoch 16/100\n",
      "1030/1030 [==============================] - 0s 353us/step - loss: 0.2625 - acc: 0.8786 - val_loss: 0.2633 - val_acc: 0.8876\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.90310\n",
      "Epoch 17/100\n",
      "1030/1030 [==============================] - 0s 349us/step - loss: 0.2805 - acc: 0.8825 - val_loss: 0.2598 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.90310\n",
      "Epoch 18/100\n",
      "1030/1030 [==============================] - 0s 348us/step - loss: 0.2829 - acc: 0.8854 - val_loss: 0.2572 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.90310\n",
      "Epoch 19/100\n",
      "1030/1030 [==============================] - 0s 357us/step - loss: 0.2492 - acc: 0.8874 - val_loss: 0.2562 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.90310\n",
      "Epoch 20/100\n",
      "1030/1030 [==============================] - 0s 347us/step - loss: 0.2708 - acc: 0.8981 - val_loss: 0.2548 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.90310\n",
      "Epoch 21/100\n",
      "1030/1030 [==============================] - 0s 350us/step - loss: 0.2504 - acc: 0.9039 - val_loss: 0.2574 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.90310\n",
      "Epoch 22/100\n",
      "1030/1030 [==============================] - 0s 352us/step - loss: 0.2606 - acc: 0.8942 - val_loss: 0.2652 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.90310\n",
      "Epoch 23/100\n",
      "1030/1030 [==============================] - 0s 350us/step - loss: 0.2570 - acc: 0.9000 - val_loss: 0.2566 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.90310\n",
      "Epoch 24/100\n",
      "1030/1030 [==============================] - 0s 384us/step - loss: 0.2578 - acc: 0.8883 - val_loss: 0.2610 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.90310\n",
      "Epoch 25/100\n",
      "1030/1030 [==============================] - 0s 378us/step - loss: 0.2535 - acc: 0.8961 - val_loss: 0.2602 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.90310\n",
      "Epoch 26/100\n",
      "1030/1030 [==============================] - 0s 350us/step - loss: 0.2538 - acc: 0.8806 - val_loss: 0.2625 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.90310\n",
      "Epoch 27/100\n",
      "1030/1030 [==============================] - 0s 351us/step - loss: 0.2425 - acc: 0.8854 - val_loss: 0.2629 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.90310\n",
      "Epoch 28/100\n",
      "1030/1030 [==============================] - 0s 353us/step - loss: 0.2679 - acc: 0.8961 - val_loss: 0.2581 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.90310\n",
      "Epoch 29/100\n",
      "1030/1030 [==============================] - 0s 355us/step - loss: 0.2567 - acc: 0.8922 - val_loss: 0.2660 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.90310\n",
      "Epoch 30/100\n",
      "1030/1030 [==============================] - 0s 356us/step - loss: 0.2545 - acc: 0.8942 - val_loss: 0.2544 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.90310\n",
      "Epoch 31/100\n",
      "1030/1030 [==============================] - 0s 354us/step - loss: 0.2292 - acc: 0.9049 - val_loss: 0.2591 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.90310\n",
      "Epoch 32/100\n",
      "1030/1030 [==============================] - 0s 349us/step - loss: 0.2455 - acc: 0.8961 - val_loss: 0.2542 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.90310\n",
      "Epoch 33/100\n",
      "1030/1030 [==============================] - 0s 346us/step - loss: 0.2426 - acc: 0.8990 - val_loss: 0.2624 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.90310\n",
      "Epoch 34/100\n",
      "1030/1030 [==============================] - 0s 347us/step - loss: 0.2682 - acc: 0.8816 - val_loss: 0.2618 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.90310\n",
      "Epoch 35/100\n",
      "1030/1030 [==============================] - 0s 349us/step - loss: 0.2518 - acc: 0.9000 - val_loss: 0.2561 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.90310\n",
      "Epoch 36/100\n",
      "1030/1030 [==============================] - 0s 344us/step - loss: 0.2428 - acc: 0.8883 - val_loss: 0.2556 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.90310\n",
      "Epoch 37/100\n",
      "1030/1030 [==============================] - 0s 348us/step - loss: 0.2503 - acc: 0.9029 - val_loss: 0.2622 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.90310\n",
      "Epoch 38/100\n",
      "1030/1030 [==============================] - 0s 344us/step - loss: 0.2568 - acc: 0.8874 - val_loss: 0.2702 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.90310\n",
      "Epoch 39/100\n",
      "1030/1030 [==============================] - 0s 347us/step - loss: 0.2419 - acc: 0.9000 - val_loss: 0.2656 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.90310\n",
      "Epoch 40/100\n",
      "1030/1030 [==============================] - 0s 348us/step - loss: 0.2443 - acc: 0.9019 - val_loss: 0.2619 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.90310 to 0.90698, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop2.hdf5\n",
      "Epoch 41/100\n",
      "1030/1030 [==============================] - 0s 352us/step - loss: 0.2636 - acc: 0.8883 - val_loss: 0.2524 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.90698\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 0s 348us/step - loss: 0.2460 - acc: 0.8951 - val_loss: 0.2540 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.90698\n",
      "Epoch 43/100\n",
      "1030/1030 [==============================] - 0s 349us/step - loss: 0.2488 - acc: 0.8961 - val_loss: 0.2530 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.90698\n",
      "Epoch 44/100\n",
      "1030/1030 [==============================] - 0s 336us/step - loss: 0.2393 - acc: 0.8971 - val_loss: 0.2588 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.90698\n",
      "Epoch 45/100\n",
      "1030/1030 [==============================] - 0s 356us/step - loss: 0.2370 - acc: 0.8971 - val_loss: 0.2492 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.90698\n",
      "Epoch 46/100\n",
      "1030/1030 [==============================] - 0s 346us/step - loss: 0.2597 - acc: 0.8767 - val_loss: 0.2451 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.90698\n",
      "Epoch 47/100\n",
      "1030/1030 [==============================] - 0s 350us/step - loss: 0.2423 - acc: 0.9068 - val_loss: 0.2472 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.90698\n",
      "Epoch 48/100\n",
      "1030/1030 [==============================] - 0s 346us/step - loss: 0.2588 - acc: 0.8981 - val_loss: 0.2523 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.90698\n",
      "Epoch 49/100\n",
      "1030/1030 [==============================] - 0s 345us/step - loss: 0.2664 - acc: 0.8922 - val_loss: 0.2494 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.90698\n",
      "Epoch 50/100\n",
      "1030/1030 [==============================] - 0s 349us/step - loss: 0.2497 - acc: 0.8951 - val_loss: 0.2553 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.90698\n",
      "Epoch 51/100\n",
      "1030/1030 [==============================] - 0s 347us/step - loss: 0.2358 - acc: 0.8922 - val_loss: 0.2464 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.90698\n",
      "Epoch 52/100\n",
      "1030/1030 [==============================] - 0s 349us/step - loss: 0.2389 - acc: 0.8913 - val_loss: 0.2497 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.90698\n",
      "Epoch 53/100\n",
      "1030/1030 [==============================] - 0s 346us/step - loss: 0.2575 - acc: 0.8961 - val_loss: 0.2469 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.90698\n",
      "Epoch 54/100\n",
      "1030/1030 [==============================] - 0s 350us/step - loss: 0.2437 - acc: 0.8971 - val_loss: 0.2495 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.90698\n",
      "Epoch 55/100\n",
      "1030/1030 [==============================] - 0s 349us/step - loss: 0.2316 - acc: 0.8961 - val_loss: 0.2470 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.90698\n",
      "Epoch 56/100\n",
      "1030/1030 [==============================] - 0s 345us/step - loss: 0.2471 - acc: 0.9019 - val_loss: 0.2484 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.90698\n",
      "Epoch 57/100\n",
      "1030/1030 [==============================] - 0s 348us/step - loss: 0.2518 - acc: 0.8932 - val_loss: 0.2450 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.90698\n",
      "Epoch 58/100\n",
      "1030/1030 [==============================] - 0s 348us/step - loss: 0.2377 - acc: 0.8922 - val_loss: 0.2469 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.90698\n",
      "Epoch 59/100\n",
      "1030/1030 [==============================] - 0s 352us/step - loss: 0.2496 - acc: 0.9000 - val_loss: 0.2482 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.90698\n",
      "Epoch 60/100\n",
      "1030/1030 [==============================] - 0s 350us/step - loss: 0.2398 - acc: 0.8942 - val_loss: 0.2543 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.90698\n",
      "Epoch 61/100\n",
      "1030/1030 [==============================] - 0s 348us/step - loss: 0.2301 - acc: 0.9049 - val_loss: 0.2477 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.90698\n",
      "Epoch 62/100\n",
      "1030/1030 [==============================] - 0s 353us/step - loss: 0.2562 - acc: 0.8883 - val_loss: 0.2574 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.90698\n",
      "Epoch 63/100\n",
      "1030/1030 [==============================] - 0s 348us/step - loss: 0.2457 - acc: 0.8835 - val_loss: 0.2654 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.90698\n",
      "Epoch 64/100\n",
      "1030/1030 [==============================] - 0s 346us/step - loss: 0.2255 - acc: 0.8971 - val_loss: 0.2522 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.90698\n",
      "Epoch 65/100\n",
      "1030/1030 [==============================] - 0s 347us/step - loss: 0.2319 - acc: 0.8951 - val_loss: 0.2516 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.90698\n",
      "Epoch 66/100\n",
      "1030/1030 [==============================] - 0s 348us/step - loss: 0.2358 - acc: 0.9049 - val_loss: 0.2555 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.90698\n",
      "Epoch 67/100\n",
      "1030/1030 [==============================] - 0s 351us/step - loss: 0.2418 - acc: 0.8922 - val_loss: 0.2570 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.90698\n",
      "Epoch 68/100\n",
      "1030/1030 [==============================] - 0s 348us/step - loss: 0.2518 - acc: 0.8932 - val_loss: 0.2587 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.90698\n",
      "Epoch 69/100\n",
      "1030/1030 [==============================] - 0s 350us/step - loss: 0.2469 - acc: 0.8971 - val_loss: 0.2607 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.90698\n",
      "Epoch 70/100\n",
      "1030/1030 [==============================] - 0s 347us/step - loss: 0.2540 - acc: 0.9049 - val_loss: 0.2558 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.90698\n",
      "Epoch 71/100\n",
      "1030/1030 [==============================] - 0s 346us/step - loss: 0.2315 - acc: 0.9019 - val_loss: 0.2576 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.90698\n",
      "Epoch 72/100\n",
      "1030/1030 [==============================] - 0s 348us/step - loss: 0.2401 - acc: 0.8971 - val_loss: 0.2553 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.90698\n",
      "Epoch 73/100\n",
      "1030/1030 [==============================] - 0s 351us/step - loss: 0.2512 - acc: 0.8971 - val_loss: 0.2503 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.90698\n",
      "Epoch 74/100\n",
      "1030/1030 [==============================] - 0s 359us/step - loss: 0.2416 - acc: 0.8990 - val_loss: 0.2504 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.90698\n",
      "Epoch 75/100\n",
      "1030/1030 [==============================] - 0s 359us/step - loss: 0.2340 - acc: 0.9068 - val_loss: 0.2511 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.90698\n",
      "Epoch 76/100\n",
      "1030/1030 [==============================] - 0s 348us/step - loss: 0.2430 - acc: 0.8981 - val_loss: 0.2599 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.90698\n",
      "Epoch 77/100\n",
      "1030/1030 [==============================] - 0s 355us/step - loss: 0.2338 - acc: 0.8942 - val_loss: 0.2482 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.90698\n",
      "Epoch 78/100\n",
      "1030/1030 [==============================] - 0s 358us/step - loss: 0.2386 - acc: 0.8922 - val_loss: 0.2513 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.90698\n",
      "Epoch 79/100\n",
      "1030/1030 [==============================] - 0s 395us/step - loss: 0.2461 - acc: 0.9039 - val_loss: 0.2416 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.90698\n",
      "Epoch 80/100\n",
      "1030/1030 [==============================] - 0s 403us/step - loss: 0.2276 - acc: 0.9087 - val_loss: 0.2451 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.90698\n",
      "Epoch 81/100\n",
      "1030/1030 [==============================] - 0s 419us/step - loss: 0.2420 - acc: 0.8951 - val_loss: 0.2442 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.90698\n",
      "Epoch 82/100\n",
      "1030/1030 [==============================] - 0s 389us/step - loss: 0.2379 - acc: 0.9019 - val_loss: 0.2546 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.90698\n",
      "Epoch 83/100\n",
      "1030/1030 [==============================] - 0s 398us/step - loss: 0.2562 - acc: 0.8971 - val_loss: 0.2519 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.90698\n",
      "Epoch 84/100\n",
      "1030/1030 [==============================] - 0s 350us/step - loss: 0.2462 - acc: 0.9000 - val_loss: 0.2610 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.90698\n",
      "Epoch 85/100\n",
      "1030/1030 [==============================] - 0s 349us/step - loss: 0.2589 - acc: 0.8893 - val_loss: 0.2623 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.90698\n",
      "Epoch 86/100\n",
      "1030/1030 [==============================] - 0s 348us/step - loss: 0.2404 - acc: 0.8971 - val_loss: 0.2661 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.90698\n",
      "Epoch 87/100\n",
      "1030/1030 [==============================] - 0s 351us/step - loss: 0.2371 - acc: 0.9010 - val_loss: 0.2587 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.90698\n",
      "Epoch 88/100\n",
      "1030/1030 [==============================] - 0s 349us/step - loss: 0.2321 - acc: 0.8990 - val_loss: 0.2553 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.90698\n",
      "Epoch 89/100\n",
      "1030/1030 [==============================] - 0s 349us/step - loss: 0.2317 - acc: 0.9049 - val_loss: 0.2554 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00089: val_acc improved from 0.90698 to 0.91085, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop2.hdf5\n",
      "Epoch 90/100\n",
      "1030/1030 [==============================] - 0s 349us/step - loss: 0.2413 - acc: 0.9019 - val_loss: 0.2569 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.91085\n",
      "Epoch 91/100\n",
      "1030/1030 [==============================] - 0s 348us/step - loss: 0.2410 - acc: 0.9000 - val_loss: 0.2554 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.91085\n",
      "Epoch 92/100\n",
      "1030/1030 [==============================] - 0s 398us/step - loss: 0.2502 - acc: 0.8932 - val_loss: 0.2599 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.91085\n",
      "Epoch 93/100\n",
      "1030/1030 [==============================] - 0s 387us/step - loss: 0.2318 - acc: 0.8961 - val_loss: 0.2524 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.91085\n",
      "Epoch 94/100\n",
      "1030/1030 [==============================] - 0s 396us/step - loss: 0.2258 - acc: 0.9058 - val_loss: 0.2538 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.91085\n",
      "Epoch 95/100\n",
      "1030/1030 [==============================] - 0s 349us/step - loss: 0.2381 - acc: 0.8913 - val_loss: 0.2572 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.91085\n",
      "Epoch 96/100\n",
      "1030/1030 [==============================] - 0s 360us/step - loss: 0.2289 - acc: 0.9039 - val_loss: 0.2546 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.91085\n",
      "Epoch 97/100\n",
      "1030/1030 [==============================] - 0s 366us/step - loss: 0.2427 - acc: 0.8903 - val_loss: 0.2541 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.91085\n",
      "Epoch 98/100\n",
      "1030/1030 [==============================] - 0s 350us/step - loss: 0.2242 - acc: 0.9058 - val_loss: 0.2581 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.91085\n",
      "Epoch 99/100\n",
      "1030/1030 [==============================] - 0s 393us/step - loss: 0.2653 - acc: 0.8874 - val_loss: 0.2565 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.91085\n",
      "Epoch 100/100\n",
      "1030/1030 [==============================] - 0s 395us/step - loss: 0.2435 - acc: 0.8922 - val_loss: 0.2530 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.91085\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 50, 50, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 50, 50, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 25, 25, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 12, 12, 86)        49622     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 12, 12, 86)        66650     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 86)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 6, 6, 86)          344       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 6, 6, 86)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              3171328   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 3,879,722\n",
      "Trainable params: 1,026\n",
      "Non-trainable params: 3,878,696\n",
      "_________________________________________________________________\n",
      "\n",
      "Keras CNN 1 - accuracy: 0.9031007751937985 \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      IDC(-)       0.89      0.94      0.92       143\n",
      "      IDC(+)       0.92      0.85      0.89       115\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       258\n",
      "   macro avg       0.91      0.90      0.90       258\n",
      "weighted avg       0.90      0.90      0.90       258\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "class MetricsCheckpoint(Callback):\n",
    "    \"\"\"apres chaque epoch en sauvegarde metrics\"\"\"\n",
    "    def __init__(self, savepath):\n",
    "        #constructeur de la class\n",
    "        super(MetricsCheckpoint, self).__init__()\n",
    "        self.savepath = savepath\n",
    "        self.history = {}\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        np.save(self.savepath, self.history)\n",
    "\n",
    "def plotKerasLearningCurve():\n",
    "    #en affiche juste la courbe de notre model\n",
    "    plt.figure(figsize=(10,5))\n",
    "    metrics = np.load('logs.npy')[()]\n",
    "    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n",
    "    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n",
    "        l = np.array(metrics[k])\n",
    "        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n",
    "        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n",
    "        y = l[x]\n",
    "        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n",
    "        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n",
    "    plt.legend(loc=4)\n",
    "    plt.axis([0, None, None, None]);\n",
    "    plt.grid()\n",
    "    plt.xlabel('nombre d epoques')\n",
    "def runKerasCNN(a,b,c,d):\n",
    "    \"\"\"\n",
    "    en a utiliser ce lien\n",
    "    https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n",
    "    en a utilise run model qui marche bien sur MNIST sur notre dataset\n",
    "    \"\"\"\n",
    "    batch_size = 128\n",
    "    num_classes = 2\n",
    "    epochs = 5\n",
    "    img_rows, img_cols = X_train.shape[1],X_train.shape[2]\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "    x_train = a\n",
    "    y_train = b\n",
    "    x_test = c\n",
    "    y_test = d   \n",
    "    model = Sequential()\n",
    "    #test d'un premier model\n",
    "    #test d'un premier model\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu', input_shape = input_shape))\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation = \"softmax\"))\n",
    "    # load weights\n",
    "    model.load_weights(\"weights.traint_40zoom_modelcomplex_avec_crop.hdf5\")\n",
    "    for layer in model.layers[:20]:\n",
    "        layer.trainable = False\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    filepath=\"weights.traint_40_100_zoom_modelcomplex_avec_crop2.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    history =model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              verbose=1,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),callbacks=callbacks_list)\n",
    "    model.summary()\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('\\nKeras CNN 1 - accuracy:', score[1],'\\n')\n",
    "    y_pred = model.predict(c) \n",
    "    map_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\n",
    "    print('\\n', sklearn.metrics.classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='')\n",
    "    Y_pred_classes = np.argmax(y_pred,axis = 1) \n",
    "    Y_true = np.argmax(Y_test,axis = 1) \n",
    "    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "    plot_confusion_matrix(confusion_mtx, classes = list(map_characters.values()))\n",
    "     \n",
    "runKerasCNN(X_train, Y_train,  X_test, Y_test)\n",
    "#plotKerasLearningCurve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1030 samples, validate on 258 samples\n",
      "Epoch 1/100\n",
      "1030/1030 [==============================] - 3s 3ms/step - loss: 0.5980 - acc: 0.8883 - val_loss: 0.6414 - val_acc: 0.8566\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.85659, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop3.hdf5\n",
      "Epoch 2/100\n",
      "1030/1030 [==============================] - 1s 616us/step - loss: 0.2499 - acc: 0.9097 - val_loss: 0.5579 - val_acc: 0.8798\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.85659 to 0.87984, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop3.hdf5\n",
      "Epoch 3/100\n",
      "1030/1030 [==============================] - 1s 625us/step - loss: 0.1960 - acc: 0.9194 - val_loss: 0.2272 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.87984 to 0.89922, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop3.hdf5\n",
      "Epoch 4/100\n",
      "1030/1030 [==============================] - 1s 631us/step - loss: 0.1367 - acc: 0.9417 - val_loss: 0.3543 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.89922 to 0.91473, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop3.hdf5\n",
      "Epoch 5/100\n",
      "1030/1030 [==============================] - 1s 630us/step - loss: 0.1243 - acc: 0.9485 - val_loss: 0.3606 - val_acc: 0.8566\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.91473\n",
      "Epoch 6/100\n",
      "1030/1030 [==============================] - 1s 704us/step - loss: 0.1789 - acc: 0.9291 - val_loss: 0.5924 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91473\n",
      "Epoch 7/100\n",
      "1030/1030 [==============================] - 1s 647us/step - loss: 0.1551 - acc: 0.9476 - val_loss: 0.1686 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.91473 to 0.92636, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop3.hdf5\n",
      "Epoch 8/100\n",
      "1030/1030 [==============================] - 1s 687us/step - loss: 0.1238 - acc: 0.9515 - val_loss: 0.1744 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.92636 to 0.93023, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop3.hdf5\n",
      "Epoch 9/100\n",
      "1030/1030 [==============================] - 1s 632us/step - loss: 0.1044 - acc: 0.9563 - val_loss: 0.2513 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.93023\n",
      "Epoch 10/100\n",
      "1030/1030 [==============================] - 1s 625us/step - loss: 0.1099 - acc: 0.9592 - val_loss: 0.1894 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.93023 to 0.94186, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop3.hdf5\n",
      "Epoch 11/100\n",
      "1030/1030 [==============================] - 1s 628us/step - loss: 0.0788 - acc: 0.9699 - val_loss: 0.2078 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.94186\n",
      "Epoch 12/100\n",
      "1030/1030 [==============================] - 1s 619us/step - loss: 0.0671 - acc: 0.9718 - val_loss: 0.1862 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.94186\n",
      "Epoch 13/100\n",
      "1030/1030 [==============================] - 1s 611us/step - loss: 0.0897 - acc: 0.9680 - val_loss: 0.2076 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.94186\n",
      "Epoch 14/100\n",
      "1030/1030 [==============================] - 1s 611us/step - loss: 0.0355 - acc: 0.9874 - val_loss: 0.1846 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.94186\n",
      "Epoch 15/100\n",
      "1030/1030 [==============================] - 1s 605us/step - loss: 0.0482 - acc: 0.9854 - val_loss: 0.3070 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.94186\n",
      "Epoch 16/100\n",
      "1030/1030 [==============================] - 1s 610us/step - loss: 0.0589 - acc: 0.9767 - val_loss: 0.1617 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.94186\n",
      "Epoch 17/100\n",
      "1030/1030 [==============================] - 1s 616us/step - loss: 0.0832 - acc: 0.9816 - val_loss: 0.2481 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.94186\n",
      "Epoch 18/100\n",
      "1030/1030 [==============================] - 1s 610us/step - loss: 0.0558 - acc: 0.9767 - val_loss: 0.1910 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.94186\n",
      "Epoch 19/100\n",
      "1030/1030 [==============================] - 1s 608us/step - loss: 0.0429 - acc: 0.9874 - val_loss: 0.1942 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.94186\n",
      "Epoch 20/100\n",
      "1030/1030 [==============================] - 1s 607us/step - loss: 0.0682 - acc: 0.9777 - val_loss: 0.1834 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.94186\n",
      "Epoch 21/100\n",
      "1030/1030 [==============================] - 1s 602us/step - loss: 0.0364 - acc: 0.9864 - val_loss: 0.1670 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.94186\n",
      "Epoch 22/100\n",
      "1030/1030 [==============================] - 1s 614us/step - loss: 0.0468 - acc: 0.9806 - val_loss: 0.2185 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.94186\n",
      "Epoch 23/100\n",
      "1030/1030 [==============================] - 1s 607us/step - loss: 0.0309 - acc: 0.9864 - val_loss: 0.1825 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.94186\n",
      "Epoch 24/100\n",
      "1030/1030 [==============================] - 1s 611us/step - loss: 0.0311 - acc: 0.9864 - val_loss: 0.2364 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.94186\n",
      "Epoch 25/100\n",
      "1030/1030 [==============================] - 1s 614us/step - loss: 0.0286 - acc: 0.9883 - val_loss: 0.1945 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.94186\n",
      "Epoch 26/100\n",
      "1030/1030 [==============================] - 1s 628us/step - loss: 0.0223 - acc: 0.9932 - val_loss: 0.2101 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.94186\n",
      "Epoch 27/100\n",
      "1030/1030 [==============================] - 1s 622us/step - loss: 0.0185 - acc: 0.9913 - val_loss: 0.2943 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.94186\n",
      "Epoch 28/100\n",
      "1030/1030 [==============================] - 1s 615us/step - loss: 0.0509 - acc: 0.9825 - val_loss: 0.2808 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.94186\n",
      "Epoch 29/100\n",
      "1030/1030 [==============================] - 1s 614us/step - loss: 0.0550 - acc: 0.9864 - val_loss: 0.6186 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.94186\n",
      "Epoch 30/100\n",
      "1030/1030 [==============================] - 1s 611us/step - loss: 0.0960 - acc: 0.9699 - val_loss: 0.2977 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.94186\n",
      "Epoch 31/100\n",
      "1030/1030 [==============================] - 1s 614us/step - loss: 0.0220 - acc: 0.9922 - val_loss: 0.3006 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.94186\n",
      "Epoch 32/100\n",
      "1030/1030 [==============================] - 1s 609us/step - loss: 0.0278 - acc: 0.9922 - val_loss: 0.1861 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.94186\n",
      "Epoch 33/100\n",
      "1030/1030 [==============================] - 1s 612us/step - loss: 0.0133 - acc: 0.9951 - val_loss: 0.1852 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.94186 to 0.94574, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop3.hdf5\n",
      "Epoch 34/100\n",
      "1030/1030 [==============================] - 1s 624us/step - loss: 0.0243 - acc: 0.9903 - val_loss: 0.1777 - val_acc: 0.9496\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.94574 to 0.94961, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop3.hdf5\n",
      "Epoch 35/100\n",
      "1030/1030 [==============================] - 1s 618us/step - loss: 0.0233 - acc: 0.9951 - val_loss: 0.1963 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.94961\n",
      "Epoch 36/100\n",
      "1030/1030 [==============================] - 1s 613us/step - loss: 0.0275 - acc: 0.9951 - val_loss: 0.2385 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.94961\n",
      "Epoch 37/100\n",
      "1030/1030 [==============================] - 1s 615us/step - loss: 0.0241 - acc: 0.9932 - val_loss: 0.7994 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.94961\n",
      "Epoch 38/100\n",
      "1030/1030 [==============================] - 1s 615us/step - loss: 0.0666 - acc: 0.9883 - val_loss: 0.2745 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.94961\n",
      "Epoch 39/100\n",
      "1030/1030 [==============================] - 1s 615us/step - loss: 0.0697 - acc: 0.9825 - val_loss: 0.2126 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.94961\n",
      "Epoch 40/100\n",
      "1030/1030 [==============================] - 1s 608us/step - loss: 0.0397 - acc: 0.9825 - val_loss: 0.2647 - val_acc: 0.9225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00040: val_acc did not improve from 0.94961\n",
      "Epoch 41/100\n",
      "1030/1030 [==============================] - 1s 608us/step - loss: 0.0282 - acc: 0.9913 - val_loss: 0.2083 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.94961\n",
      "Epoch 42/100\n",
      "1030/1030 [==============================] - 1s 607us/step - loss: 0.0289 - acc: 0.9922 - val_loss: 0.1542 - val_acc: 0.9496\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.94961\n",
      "Epoch 43/100\n",
      "1030/1030 [==============================] - 1s 607us/step - loss: 0.0186 - acc: 0.9913 - val_loss: 0.3341 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.94961\n",
      "Epoch 44/100\n",
      "1030/1030 [==============================] - 1s 610us/step - loss: 0.0315 - acc: 0.9951 - val_loss: 0.3052 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.94961\n",
      "Epoch 45/100\n",
      "1030/1030 [==============================] - 1s 607us/step - loss: 0.0297 - acc: 0.9883 - val_loss: 0.2957 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.94961\n",
      "Epoch 46/100\n",
      "1030/1030 [==============================] - 1s 605us/step - loss: 0.0449 - acc: 0.9845 - val_loss: 0.2820 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.94961\n",
      "Epoch 47/100\n",
      "1030/1030 [==============================] - 1s 613us/step - loss: 0.0232 - acc: 0.9942 - val_loss: 0.2472 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.94961\n",
      "Epoch 48/100\n",
      "1030/1030 [==============================] - 1s 605us/step - loss: 0.0412 - acc: 0.9893 - val_loss: 0.1968 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.94961\n",
      "Epoch 49/100\n",
      "1030/1030 [==============================] - 1s 609us/step - loss: 0.0115 - acc: 0.9951 - val_loss: 0.1965 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.94961\n",
      "Epoch 50/100\n",
      "1030/1030 [==============================] - 1s 603us/step - loss: 0.0381 - acc: 0.9893 - val_loss: 0.3690 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.94961\n",
      "Epoch 51/100\n",
      "1030/1030 [==============================] - 1s 607us/step - loss: 0.0495 - acc: 0.9864 - val_loss: 0.3232 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.94961\n",
      "Epoch 52/100\n",
      "1030/1030 [==============================] - 1s 606us/step - loss: 0.0153 - acc: 0.9942 - val_loss: 0.2602 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.94961\n",
      "Epoch 53/100\n",
      "1030/1030 [==============================] - 1s 600us/step - loss: 0.0607 - acc: 0.9845 - val_loss: 0.1907 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.94961\n",
      "Epoch 54/100\n",
      "1030/1030 [==============================] - 1s 612us/step - loss: 0.0301 - acc: 0.9883 - val_loss: 0.2300 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.94961\n",
      "Epoch 55/100\n",
      "1030/1030 [==============================] - 1s 607us/step - loss: 0.0058 - acc: 0.9981 - val_loss: 0.2237 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.94961\n",
      "Epoch 56/100\n",
      "1030/1030 [==============================] - 1s 608us/step - loss: 0.0079 - acc: 0.9971 - val_loss: 0.2381 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.94961\n",
      "Epoch 57/100\n",
      "1030/1030 [==============================] - 1s 607us/step - loss: 0.0194 - acc: 0.9942 - val_loss: 0.2890 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.94961\n",
      "Epoch 58/100\n",
      "1030/1030 [==============================] - 1s 607us/step - loss: 0.0551 - acc: 0.9883 - val_loss: 0.4223 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.94961\n",
      "Epoch 59/100\n",
      "1030/1030 [==============================] - 1s 607us/step - loss: 0.0697 - acc: 0.9835 - val_loss: 0.2420 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.94961\n",
      "Epoch 60/100\n",
      "1030/1030 [==============================] - 1s 609us/step - loss: 0.0251 - acc: 0.9932 - val_loss: 0.2094 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.94961\n",
      "Epoch 61/100\n",
      "1030/1030 [==============================] - 1s 607us/step - loss: 0.0499 - acc: 0.9854 - val_loss: 0.2096 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.94961\n",
      "Epoch 62/100\n",
      "1030/1030 [==============================] - 1s 609us/step - loss: 0.0078 - acc: 0.9961 - val_loss: 0.1935 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.94961\n",
      "Epoch 63/100\n",
      "1030/1030 [==============================] - 1s 618us/step - loss: 0.0100 - acc: 0.9951 - val_loss: 0.2414 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.94961\n",
      "Epoch 64/100\n",
      "1030/1030 [==============================] - 1s 615us/step - loss: 0.0178 - acc: 0.9971 - val_loss: 0.2940 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.94961\n",
      "Epoch 65/100\n",
      "1030/1030 [==============================] - 1s 613us/step - loss: 0.0378 - acc: 0.9913 - val_loss: 0.2261 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.94961\n",
      "Epoch 66/100\n",
      "1030/1030 [==============================] - 1s 610us/step - loss: 0.0270 - acc: 0.9951 - val_loss: 0.2658 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.94961\n",
      "Epoch 67/100\n",
      "1030/1030 [==============================] - 1s 612us/step - loss: 0.0213 - acc: 0.9932 - val_loss: 0.2246 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.94961\n",
      "Epoch 68/100\n",
      "1030/1030 [==============================] - 1s 610us/step - loss: 0.0311 - acc: 0.9932 - val_loss: 0.2823 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.94961\n",
      "Epoch 69/100\n",
      "1030/1030 [==============================] - 1s 609us/step - loss: 0.0242 - acc: 0.9913 - val_loss: 0.2406 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.94961\n",
      "Epoch 70/100\n",
      "1030/1030 [==============================] - 1s 606us/step - loss: 0.0386 - acc: 0.9893 - val_loss: 0.1940 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.94961\n",
      "Epoch 71/100\n",
      "1030/1030 [==============================] - 1s 609us/step - loss: 0.0192 - acc: 0.9932 - val_loss: 0.3224 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.94961\n",
      "Epoch 72/100\n",
      "1030/1030 [==============================] - 1s 607us/step - loss: 0.0288 - acc: 0.9913 - val_loss: 0.2184 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00072: val_acc improved from 0.94961 to 0.95349, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop3.hdf5\n",
      "Epoch 73/100\n",
      "1030/1030 [==============================] - 1s 632us/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.5099 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.95349\n",
      "Epoch 74/100\n",
      "1030/1030 [==============================] - 1s 607us/step - loss: 0.0454 - acc: 0.9874 - val_loss: 0.2209 - val_acc: 0.9651\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.95349 to 0.96512, saving model to weights.traint_40_100_zoom_modelcomplex_avec_crop3.hdf5\n",
      "Epoch 75/100\n",
      "1030/1030 [==============================] - 1s 619us/step - loss: 0.0176 - acc: 0.9951 - val_loss: 0.5366 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.96512\n",
      "Epoch 76/100\n",
      "1030/1030 [==============================] - 1s 610us/step - loss: 0.0483 - acc: 0.9835 - val_loss: 0.2587 - val_acc: 0.9419\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.96512\n",
      "Epoch 77/100\n",
      "1030/1030 [==============================] - 1s 603us/step - loss: 0.0179 - acc: 0.9932 - val_loss: 0.2763 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.96512\n",
      "Epoch 78/100\n",
      "1030/1030 [==============================] - 1s 611us/step - loss: 0.0151 - acc: 0.9913 - val_loss: 0.2613 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.96512\n",
      "Epoch 79/100\n",
      "1030/1030 [==============================] - 1s 608us/step - loss: 0.0183 - acc: 0.9932 - val_loss: 0.2524 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.96512\n",
      "Epoch 80/100\n",
      "1030/1030 [==============================] - 1s 607us/step - loss: 0.0038 - acc: 0.9990 - val_loss: 0.2385 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.96512\n",
      "Epoch 81/100\n",
      "1030/1030 [==============================] - 1s 608us/step - loss: 0.0065 - acc: 0.9971 - val_loss: 0.4593 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.96512\n",
      "Epoch 82/100\n",
      "1030/1030 [==============================] - 1s 610us/step - loss: 0.0155 - acc: 0.9951 - val_loss: 0.3799 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.96512\n",
      "Epoch 83/100\n",
      "1030/1030 [==============================] - 1s 609us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.3685 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.96512\n",
      "Epoch 84/100\n",
      "1030/1030 [==============================] - 1s 610us/step - loss: 0.0083 - acc: 0.9932 - val_loss: 0.3331 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.96512\n",
      "Epoch 85/100\n",
      "1030/1030 [==============================] - 1s 607us/step - loss: 0.0121 - acc: 0.9942 - val_loss: 0.6515 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.96512\n",
      "Epoch 86/100\n",
      "1030/1030 [==============================] - 1s 606us/step - loss: 0.0479 - acc: 0.9893 - val_loss: 0.4408 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.96512\n",
      "Epoch 87/100\n",
      "1030/1030 [==============================] - 1s 605us/step - loss: 0.0174 - acc: 0.9903 - val_loss: 0.2928 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.96512\n",
      "Epoch 88/100\n",
      "1030/1030 [==============================] - 1s 614us/step - loss: 0.0158 - acc: 0.9981 - val_loss: 0.3157 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.96512\n",
      "Epoch 89/100\n",
      "1030/1030 [==============================] - 1s 608us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.2848 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.96512\n",
      "Epoch 90/100\n",
      "1030/1030 [==============================] - 1s 608us/step - loss: 0.0053 - acc: 0.9981 - val_loss: 0.8260 - val_acc: 0.8760\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.96512\n",
      "Epoch 91/100\n",
      "1030/1030 [==============================] - 1s 609us/step - loss: 0.0303 - acc: 0.9903 - val_loss: 0.3462 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.96512\n",
      "Epoch 92/100\n",
      "1030/1030 [==============================] - 1s 610us/step - loss: 0.0023 - acc: 0.9990 - val_loss: 0.2882 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.96512\n",
      "Epoch 93/100\n",
      "1030/1030 [==============================] - 1s 606us/step - loss: 0.0060 - acc: 0.9981 - val_loss: 0.2576 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.96512\n",
      "Epoch 94/100\n",
      "1030/1030 [==============================] - 1s 608us/step - loss: 0.0117 - acc: 0.9942 - val_loss: 0.2976 - val_acc: 0.9302\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.96512\n",
      "Epoch 95/100\n",
      "1030/1030 [==============================] - 1s 626us/step - loss: 0.0179 - acc: 0.9971 - val_loss: 0.4719 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.96512\n",
      "Epoch 96/100\n",
      "1030/1030 [==============================] - 1s 618us/step - loss: 0.0183 - acc: 0.9932 - val_loss: 0.4011 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.96512\n",
      "Epoch 97/100\n",
      "1030/1030 [==============================] - 1s 615us/step - loss: 0.0219 - acc: 0.9961 - val_loss: 0.3253 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.96512\n",
      "Epoch 98/100\n",
      "1030/1030 [==============================] - 1s 626us/step - loss: 0.0108 - acc: 0.9951 - val_loss: 0.3232 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.96512\n",
      "Epoch 99/100\n",
      "1030/1030 [==============================] - 1s 617us/step - loss: 0.0118 - acc: 0.9961 - val_loss: 0.3664 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.96512\n",
      "Epoch 100/100\n",
      "1030/1030 [==============================] - 1s 625us/step - loss: 0.0222 - acc: 0.9942 - val_loss: 0.2997 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.96512\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 50, 50, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 50, 50, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 25, 25, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 12, 12, 86)        49622     \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 12, 12, 86)        66650     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 6, 6, 86)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 6, 6, 86)          344       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 6, 6, 86)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              3171328   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 3,879,722\n",
      "Trainable params: 3,869,150\n",
      "Non-trainable params: 10,572\n",
      "_________________________________________________________________\n",
      "\n",
      "Keras CNN 1 - accuracy: 0.9224806201550387 \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      IDC(-)       0.94      0.92      0.93       143\n",
      "      IDC(+)       0.91      0.92      0.91       115\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       258\n",
      "   macro avg       0.92      0.92      0.92       258\n",
      "weighted avg       0.92      0.92      0.92       258\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "class MetricsCheckpoint(Callback):\n",
    "    \"\"\"apres chaque epoch en sauvegarde metrics\"\"\"\n",
    "    def __init__(self, savepath):\n",
    "        #constructeur de la class\n",
    "        super(MetricsCheckpoint, self).__init__()\n",
    "        self.savepath = savepath\n",
    "        self.history = {}\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        np.save(self.savepath, self.history)\n",
    "\n",
    "def plotKerasLearningCurve():\n",
    "    #en affiche juste la courbe de notre model\n",
    "    plt.figure(figsize=(10,5))\n",
    "    metrics = np.load('logs.npy')[()]\n",
    "    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n",
    "    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n",
    "        l = np.array(metrics[k])\n",
    "        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n",
    "        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n",
    "        y = l[x]\n",
    "        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n",
    "        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n",
    "    plt.legend(loc=4)\n",
    "    plt.axis([0, None, None, None]);\n",
    "    plt.grid()\n",
    "    plt.xlabel('nombre d epoques')\n",
    "def runKerasCNN(a,b,c,d):\n",
    "    \"\"\"\n",
    "    en a utiliser ce lien\n",
    "    https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n",
    "    en a utilise run model qui marche bien sur MNIST sur notre dataset\n",
    "    \"\"\"\n",
    "    batch_size = 128\n",
    "    num_classes = 2\n",
    "    epochs = 5\n",
    "    img_rows, img_cols = X_train.shape[1],X_train.shape[2]\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "    x_train = a\n",
    "    y_train = b\n",
    "    x_test = c\n",
    "    y_test = d   \n",
    "    model = Sequential()\n",
    "    #test d'un premier model\n",
    "    #test d'un premier model\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu', input_shape = input_shape))\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation = \"softmax\"))\n",
    "    # load weights\n",
    "    model.load_weights(\"weights.traint_40zoom_modelcomplex_avec_crop.hdf5\")\n",
    "    for layer in model.layers[:5]:\n",
    "        layer.trainable = False\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    filepath=\"weights.traint_40_100_zoom_modelcomplex_avec_crop3.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    history =model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              verbose=1,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),callbacks=callbacks_list)\n",
    "    model.summary()\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('\\nKeras CNN 1 - accuracy:', score[1],'\\n')\n",
    "    y_pred = model.predict(c) \n",
    "    map_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\n",
    "    print('\\n', sklearn.metrics.classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='')\n",
    "    Y_pred_classes = np.argmax(y_pred,axis = 1) \n",
    "    Y_true = np.argmax(Y_test,axis = 1) \n",
    "    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "    plot_confusion_matrix(confusion_mtx, classes = list(map_characters.values()))\n",
    "     \n",
    "runKerasCNN(X_train, Y_train,  X_test, Y_test)\n",
    "#plotKerasLearningCurve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 50, 50, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 50, 50, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 25, 25, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 12, 12, 86)        49622     \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 12, 12, 86)        66650     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 6, 6, 86)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 6, 6, 86)          344       \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 6, 6, 86)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 3096)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1024)              3171328   \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 3,879,722\n",
      "Trainable params: 3,879,358\n",
      "Non-trainable params: 364\n",
      "_________________________________________________________________\n",
      "\n",
      "Keras CNN 1 - accuracy: 0.9651162790697675 \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      IDC(-)       0.97      0.96      0.96       123\n",
      "      IDC(+)       0.96      0.97      0.97       135\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       258\n",
      "   macro avg       0.97      0.96      0.97       258\n",
      "weighted avg       0.97      0.97      0.97       258\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# charger des images formes (5547, 50, 50, 3)\n",
    "X = np.load('D:/test cancer rbreast/crop/zoom_100m.npy')  \n",
    "\n",
    "# charger des images  (5547,1); (0 = no cancer, 1 = cancer)\n",
    "Y = np.load('D:/test cancer rbreast/crop/zoom_100m_label.npy')   \n",
    "perm_array = np.arange(len(X))\n",
    "#arrange genere tous toute les val jusqua la longuer de x_images\n",
    "np.random.shuffle(perm_array)\n",
    "#il melange les images\n",
    "X = X[perm_array]\n",
    "Y = Y[perm_array]\n",
    "#en split notre dataset 80 % 20 %\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "# en redduit la taille de l'echantillon au cas ou en avais trop d'images \n",
    "#pour pas que ca prend trop de temps pour le pc \n",
    "#mais ici c'est pas le cas donc en commente ce code\n",
    "#X_train = X_train[0:30000] \n",
    "#Y_train = Y_train[0:30000]\n",
    "#X_test = X_test[0:30000] \n",
    "#Y_test = Y_test[0:30000]\n",
    "\n",
    "# normalizer nos donnees \n",
    "#en pourrais utiliser d'autre methodes aussi mais celle la c'est bien \n",
    "X_train = X_train / 256.0\n",
    "X_test = X_test / 256.0\n",
    "#methode qu'on a trouver sur internet et qu'on a utiliser \n",
    "X_trainShape = X_train.shape[1]*X_train.shape[2]*X_train.shape[3]\n",
    "X_testShape = X_test.shape[1]*X_test.shape[2]*X_test.shape[3]\n",
    "#en applatit les donnees en gros en les transfrome en une matrice 1 seul dimmenssion nbr elem*(width*height*channel)\n",
    "X_trainFlat = X_train.reshape(X_train.shape[0], X_trainShape)\n",
    "X_testFlat = X_test.reshape(X_test.shape[0], X_testShape)\n",
    "Y_train = to_categorical(Y_train, num_classes = 2)\n",
    "Y_test = to_categorical(Y_test, num_classes = 2)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "class MetricsCheckpoint(Callback):\n",
    "    \"\"\"apres chaque epoch en sauvegarde metrics\"\"\"\n",
    "    def __init__(self, savepath):\n",
    "        #constructeur de la class\n",
    "        super(MetricsCheckpoint, self).__init__()\n",
    "        self.savepath = savepath\n",
    "        self.history = {}\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        np.save(self.savepath, self.history)\n",
    "\n",
    "def plotKerasLearningCurve():\n",
    "    #en affiche juste la courbe de notre model\n",
    "    plt.figure(figsize=(10,5))\n",
    "    metrics = np.load('logs.npy')[()]\n",
    "    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n",
    "    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n",
    "        l = np.array(metrics[k])\n",
    "        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n",
    "        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n",
    "        y = l[x]\n",
    "        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n",
    "        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n",
    "    plt.legend(loc=4)\n",
    "    plt.axis([0, None, None, None]);\n",
    "    plt.grid()\n",
    "    plt.xlabel('nombre d epoques')\n",
    "def runKerasCNN(a,b,c,d):\n",
    "    \"\"\"\n",
    "    en a utiliser ce lien\n",
    "    https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n",
    "    en a utilise run model qui marche bien sur MNIST sur notre dataset\n",
    "    \"\"\"\n",
    "    batch_size = 128\n",
    "    num_classes = 2\n",
    "    epochs = 5\n",
    "    img_rows, img_cols = X_train.shape[1],X_train.shape[2]\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "    x_train = a\n",
    "    y_train = b\n",
    "    x_test = c\n",
    "    y_test = d   \n",
    "    model = Sequential()\n",
    "    #test d'un premier model\n",
    "    #test d'un premier model\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu', input_shape = input_shape))\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation = \"softmax\"))\n",
    "    # load weights\n",
    "    model.load_weights(\"weights.traint_40_100_zoom_modelcomplex_avec_crop.hdf5\")\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('\\nKeras CNN 1 - accuracy:', score[1],'\\n')\n",
    "    y_pred = model.predict(c) \n",
    "    map_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\n",
    "    print('\\n', sklearn.metrics.classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='')\n",
    "    Y_pred_classes = np.argmax(y_pred,axis = 1) \n",
    "    Y_true = np.argmax(Y_test,axis = 1) \n",
    "    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "    plot_confusion_matrix(confusion_mtx, classes = list(map_characters.values()))\n",
    "     \n",
    "runKerasCNN(X_train, Y_train,  X_test, Y_test)\n",
    "#plotKerasLearningCurve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 50, 50, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 50, 50, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 25, 25, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 12, 12, 86)        49622     \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 12, 12, 86)        66650     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 6, 6, 86)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 6, 6, 86)          344       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 6, 6, 86)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3096)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              3171328   \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 3,879,722\n",
      "Trainable params: 3,879,358\n",
      "Non-trainable params: 364\n",
      "_________________________________________________________________\n",
      "\n",
      "Keras CNN 1 - accuracy: 0.8798449612403101 \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      IDC(-)       0.84      0.91      0.88       120\n",
      "      IDC(+)       0.91      0.86      0.88       138\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       258\n",
      "   macro avg       0.88      0.88      0.88       258\n",
      "weighted avg       0.88      0.88      0.88       258\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# charger des images formes (5547, 50, 50, 3)\n",
    "X = np.load('D:/test cancer rbreast/crop/zoom_100m.npy')  \n",
    "\n",
    "# charger des images  (5547,1); (0 = no cancer, 1 = cancer)\n",
    "Y = np.load('D:/test cancer rbreast/crop/zoom_100m_label.npy')   \n",
    "perm_array = np.arange(len(X))\n",
    "#arrange genere tous toute les val jusqua la longuer de x_images\n",
    "np.random.shuffle(perm_array)\n",
    "#il melange les images\n",
    "X = X[perm_array]\n",
    "Y = Y[perm_array]\n",
    "#en split notre dataset 80 % 20 %\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "# en redduit la taille de l'echantillon au cas ou en avais trop d'images \n",
    "#pour pas que ca prend trop de temps pour le pc \n",
    "#mais ici c'est pas le cas donc en commente ce code\n",
    "#X_train = X_train[0:30000] \n",
    "#Y_train = Y_train[0:30000]\n",
    "#X_test = X_test[0:30000] \n",
    "#Y_test = Y_test[0:30000]\n",
    "\n",
    "# normalizer nos donnees \n",
    "#en pourrais utiliser d'autre methodes aussi mais celle la c'est bien \n",
    "X_train = X_train / 256.0\n",
    "X_test = X_test / 256.0\n",
    "#methode qu'on a trouver sur internet et qu'on a utiliser \n",
    "X_trainShape = X_train.shape[1]*X_train.shape[2]*X_train.shape[3]\n",
    "X_testShape = X_test.shape[1]*X_test.shape[2]*X_test.shape[3]\n",
    "#en applatit les donnees en gros en les transfrome en une matrice 1 seul dimmenssion nbr elem*(width*height*channel)\n",
    "X_trainFlat = X_train.reshape(X_train.shape[0], X_trainShape)\n",
    "X_testFlat = X_test.reshape(X_test.shape[0], X_testShape)\n",
    "Y_train = to_categorical(Y_train, num_classes = 2)\n",
    "Y_test = to_categorical(Y_test, num_classes = 2)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "class MetricsCheckpoint(Callback):\n",
    "    \"\"\"apres chaque epoch en sauvegarde metrics\"\"\"\n",
    "    def __init__(self, savepath):\n",
    "        #constructeur de la class\n",
    "        super(MetricsCheckpoint, self).__init__()\n",
    "        self.savepath = savepath\n",
    "        self.history = {}\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        np.save(self.savepath, self.history)\n",
    "\n",
    "def plotKerasLearningCurve():\n",
    "    #en affiche juste la courbe de notre model\n",
    "    plt.figure(figsize=(10,5))\n",
    "    metrics = np.load('logs.npy')[()]\n",
    "    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n",
    "    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n",
    "        l = np.array(metrics[k])\n",
    "        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n",
    "        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n",
    "        y = l[x]\n",
    "        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n",
    "        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n",
    "    plt.legend(loc=4)\n",
    "    plt.axis([0, None, None, None]);\n",
    "    plt.grid()\n",
    "    plt.xlabel('nombre d epoques')\n",
    "def runKerasCNN(a,b,c,d):\n",
    "    \"\"\"\n",
    "    en a utiliser ce lien\n",
    "    https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n",
    "    en a utilise run model qui marche bien sur MNIST sur notre dataset\n",
    "    \"\"\"\n",
    "    batch_size = 128\n",
    "    num_classes = 2\n",
    "    epochs = 5\n",
    "    img_rows, img_cols = X_train.shape[1],X_train.shape[2]\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "    x_train = a\n",
    "    y_train = b\n",
    "    x_test = c\n",
    "    y_test = d   \n",
    "    model = Sequential()\n",
    "    #test d'un premier model\n",
    "    #test d'un premier model\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu', input_shape = input_shape))\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation = \"softmax\"))\n",
    "    # load weights\n",
    "    model.load_weights(\"weights.traint_40_100_zoom_modelcomplex_avec_crop2.hdf5\")\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('\\nKeras CNN 1 - accuracy:', score[1],'\\n')\n",
    "    y_pred = model.predict(c) \n",
    "    map_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\n",
    "    print('\\n', sklearn.metrics.classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='')\n",
    "    Y_pred_classes = np.argmax(y_pred,axis = 1) \n",
    "    Y_true = np.argmax(Y_test,axis = 1) \n",
    "    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "    plot_confusion_matrix(confusion_mtx, classes = list(map_characters.values()))\n",
    "     \n",
    "runKerasCNN(X_train, Y_train,  X_test, Y_test)\n",
    "#plotKerasLearningCurve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_31 (Conv2D)           (None, 50, 50, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 50, 50, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 25, 25, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 25, 25, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 25, 25, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 12, 12, 86)        49622     \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 12, 12, 86)        66650     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 6, 6, 86)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 6, 6, 86)          344       \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 6, 6, 86)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 3096)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1024)              3171328   \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 3,879,722\n",
      "Trainable params: 3,879,358\n",
      "Non-trainable params: 364\n",
      "_________________________________________________________________\n",
      "\n",
      "Keras CNN 1 - accuracy: 0.9689922480620154 \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      IDC(-)       0.95      0.98      0.97       125\n",
      "      IDC(+)       0.98      0.95      0.97       133\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       258\n",
      "   macro avg       0.97      0.97      0.97       258\n",
      "weighted avg       0.97      0.97      0.97       258\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# charger des images formes (5547, 50, 50, 3)\n",
    "X = np.load('D:/test cancer rbreast/crop/zoom_100m.npy')  \n",
    "\n",
    "# charger des images  (5547,1); (0 = no cancer, 1 = cancer)\n",
    "Y = np.load('D:/test cancer rbreast/crop/zoom_100m_label.npy')   \n",
    "perm_array = np.arange(len(X))\n",
    "#arrange genere tous toute les val jusqua la longuer de x_images\n",
    "np.random.shuffle(perm_array)\n",
    "#il melange les images\n",
    "X = X[perm_array]\n",
    "Y = Y[perm_array]\n",
    "#en split notre dataset 80 % 20 %\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "# en redduit la taille de l'echantillon au cas ou en avais trop d'images \n",
    "#pour pas que ca prend trop de temps pour le pc \n",
    "#mais ici c'est pas le cas donc en commente ce code\n",
    "#X_train = X_train[0:30000] \n",
    "#Y_train = Y_train[0:30000]\n",
    "#X_test = X_test[0:30000] \n",
    "#Y_test = Y_test[0:30000]\n",
    "\n",
    "# normalizer nos donnees \n",
    "#en pourrais utiliser d'autre methodes aussi mais celle la c'est bien \n",
    "X_train = X_train / 256.0\n",
    "X_test = X_test / 256.0\n",
    "#methode qu'on a trouver sur internet et qu'on a utiliser \n",
    "X_trainShape = X_train.shape[1]*X_train.shape[2]*X_train.shape[3]\n",
    "X_testShape = X_test.shape[1]*X_test.shape[2]*X_test.shape[3]\n",
    "#en applatit les donnees en gros en les transfrome en une matrice 1 seul dimmenssion nbr elem*(width*height*channel)\n",
    "X_trainFlat = X_train.reshape(X_train.shape[0], X_trainShape)\n",
    "X_testFlat = X_test.reshape(X_test.shape[0], X_testShape)\n",
    "Y_train = to_categorical(Y_train, num_classes = 2)\n",
    "Y_test = to_categorical(Y_test, num_classes = 2)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "class MetricsCheckpoint(Callback):\n",
    "    \"\"\"apres chaque epoch en sauvegarde metrics\"\"\"\n",
    "    def __init__(self, savepath):\n",
    "        #constructeur de la class\n",
    "        super(MetricsCheckpoint, self).__init__()\n",
    "        self.savepath = savepath\n",
    "        self.history = {}\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        np.save(self.savepath, self.history)\n",
    "\n",
    "def plotKerasLearningCurve():\n",
    "    #en affiche juste la courbe de notre model\n",
    "    plt.figure(figsize=(10,5))\n",
    "    metrics = np.load('logs.npy')[()]\n",
    "    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n",
    "    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n",
    "        l = np.array(metrics[k])\n",
    "        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n",
    "        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n",
    "        y = l[x]\n",
    "        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n",
    "        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n",
    "    plt.legend(loc=4)\n",
    "    plt.axis([0, None, None, None]);\n",
    "    plt.grid()\n",
    "    plt.xlabel('nombre d epoques')\n",
    "def runKerasCNN(a,b,c,d):\n",
    "    \"\"\"\n",
    "    en a utiliser ce lien\n",
    "    https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n",
    "    en a utilise run model qui marche bien sur MNIST sur notre dataset\n",
    "    \"\"\"\n",
    "    batch_size = 128\n",
    "    num_classes = 2\n",
    "    epochs = 5\n",
    "    img_rows, img_cols = X_train.shape[1],X_train.shape[2]\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "    x_train = a\n",
    "    y_train = b\n",
    "    x_test = c\n",
    "    y_test = d   \n",
    "    model = Sequential()\n",
    "    #test d'un premier model\n",
    "    #test d'un premier model\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu', input_shape = input_shape))\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation = \"softmax\"))\n",
    "    # load weights\n",
    "    model.load_weights(\"weights.traint_40_100_zoom_modelcomplex_avec_crop3.hdf5\")\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('\\nKeras CNN 1 - accuracy:', score[1],'\\n')\n",
    "    y_pred = model.predict(c) \n",
    "    map_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\n",
    "    print('\\n', sklearn.metrics.classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='')\n",
    "    Y_pred_classes = np.argmax(y_pred,axis = 1) \n",
    "    Y_true = np.argmax(Y_test,axis = 1) \n",
    "    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "    plot_confusion_matrix(confusion_mtx, classes = list(map_characters.values()))\n",
    "     \n",
    "runKerasCNN(X_train, Y_train,  X_test, Y_test)\n",
    "#plotKerasLearningCurve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "33/33 [==============================] - 3s 106ms/step - loss: 0.7142 - acc: 0.4943 - val_loss: 0.6949 - val_acc: 0.4612\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.46124, saving model to weights.data_aug.hdf5\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 1s 42ms/step - loss: 0.6952 - acc: 0.4797 - val_loss: 0.6889 - val_acc: 0.5581\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.46124 to 0.55814, saving model to weights.data_aug.hdf5\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 1s 45ms/step - loss: 0.6946 - acc: 0.4920 - val_loss: 0.6945 - val_acc: 0.4612\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.55814\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 1s 43ms/step - loss: 0.6936 - acc: 0.5106 - val_loss: 0.6946 - val_acc: 0.4612\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.55814\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 1s 44ms/step - loss: 0.6909 - acc: 0.5195 - val_loss: 0.7126 - val_acc: 0.4612\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.55814\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 2s 48ms/step - loss: 0.6903 - acc: 0.5535 - val_loss: 0.6879 - val_acc: 0.5388\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.55814\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 2s 51ms/step - loss: 0.7077 - acc: 0.5131 - val_loss: 0.6812 - val_acc: 0.5930\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.55814 to 0.59302, saving model to weights.data_aug.hdf5\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 2s 49ms/step - loss: 0.6862 - acc: 0.5155 - val_loss: 0.6820 - val_acc: 0.7287\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.59302 to 0.72868, saving model to weights.data_aug.hdf5\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 2s 66ms/step - loss: 0.6783 - acc: 0.6031 - val_loss: 0.6608 - val_acc: 0.7171\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.72868\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 2s 58ms/step - loss: 0.6703 - acc: 0.6035 - val_loss: 0.6653 - val_acc: 0.5504\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.72868\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 2s 55ms/step - loss: 0.6633 - acc: 0.6109 - val_loss: 0.6856 - val_acc: 0.5504\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.72868\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 2s 65ms/step - loss: 0.6970 - acc: 0.6395 - val_loss: 0.7183 - val_acc: 0.4612\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.72868\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 2s 64ms/step - loss: 0.6158 - acc: 0.6840 - val_loss: 0.5610 - val_acc: 0.7481\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.72868 to 0.74806, saving model to weights.data_aug.hdf5\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 2s 62ms/step - loss: 0.6033 - acc: 0.6930 - val_loss: 0.5811 - val_acc: 0.7287\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.74806\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 2s 60ms/step - loss: 0.5935 - acc: 0.6979 - val_loss: 0.7125 - val_acc: 0.4651\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.74806\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 2s 48ms/step - loss: 0.5696 - acc: 0.7022 - val_loss: 0.4764 - val_acc: 0.7636\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.74806 to 0.76357, saving model to weights.data_aug.hdf5\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 1s 44ms/step - loss: 0.5694 - acc: 0.7079 - val_loss: 0.4743 - val_acc: 0.7636\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.76357\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 1s 44ms/step - loss: 0.5830 - acc: 0.6927 - val_loss: 0.5584 - val_acc: 0.7403\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.76357\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.5995 - acc: 0.6861 - val_loss: 0.5588 - val_acc: 0.7442\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.76357\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.5568 - acc: 0.7278 - val_loss: 0.4699 - val_acc: 0.7674\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.76357 to 0.76744, saving model to weights.data_aug.hdf5\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.5149 - acc: 0.7513 - val_loss: 0.4602 - val_acc: 0.7752\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.76744 to 0.77519, saving model to weights.data_aug.hdf5\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.4897 - acc: 0.7648 - val_loss: 0.4788 - val_acc: 0.7558\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.77519\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 1s 43ms/step - loss: 0.5097 - acc: 0.7617 - val_loss: 0.4645 - val_acc: 0.7868\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.77519 to 0.78682, saving model to weights.data_aug.hdf5\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 1s 42ms/step - loss: 0.5659 - acc: 0.7216 - val_loss: 0.4760 - val_acc: 0.7597\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.78682\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.4664 - acc: 0.7951 - val_loss: 0.4607 - val_acc: 0.7829\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.78682\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 1s 43ms/step - loss: 0.4851 - acc: 0.7807 - val_loss: 0.4400 - val_acc: 0.7907\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.78682 to 0.79070, saving model to weights.data_aug.hdf5\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 1s 43ms/step - loss: 0.4357 - acc: 0.8162 - val_loss: 0.4952 - val_acc: 0.7364\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.79070\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.4786 - acc: 0.7830 - val_loss: 0.4168 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.79070 to 0.79845, saving model to weights.data_aug.hdf5\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 1s 42ms/step - loss: 0.4617 - acc: 0.7822 - val_loss: 0.4020 - val_acc: 0.8101\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.79845 to 0.81008, saving model to weights.data_aug.hdf5\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 1s 42ms/step - loss: 0.4739 - acc: 0.7826 - val_loss: 0.5759 - val_acc: 0.6705\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.81008\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 1s 44ms/step - loss: 0.4735 - acc: 0.7887 - val_loss: 0.5003 - val_acc: 0.7403\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.81008\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.4557 - acc: 0.8046 - val_loss: 0.4200 - val_acc: 0.8062\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.81008\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.4253 - acc: 0.8063 - val_loss: 0.4912 - val_acc: 0.7519\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.81008\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.4215 - acc: 0.8266 - val_loss: 0.4105 - val_acc: 0.7946\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.81008\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.4722 - acc: 0.8042 - val_loss: 0.4104 - val_acc: 0.8217\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.81008 to 0.82171, saving model to weights.data_aug.hdf5\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.3815 - acc: 0.8408 - val_loss: 0.6182 - val_acc: 0.7752\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.82171\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3825 - acc: 0.8406 - val_loss: 0.4046 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.82171\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.4200 - acc: 0.8108 - val_loss: 0.3928 - val_acc: 0.8256\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.82171 to 0.82558, saving model to weights.data_aug.hdf5\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.4846 - acc: 0.7826 - val_loss: 0.4573 - val_acc: 0.7907\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.82558\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3561 - acc: 0.8616 - val_loss: 0.5868 - val_acc: 0.7791\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.82558\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.4166 - acc: 0.8167 - val_loss: 0.3715 - val_acc: 0.8256\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.82558\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3586 - acc: 0.8569 - val_loss: 0.4034 - val_acc: 0.8295\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.82558 to 0.82946, saving model to weights.data_aug.hdf5\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3985 - acc: 0.8359 - val_loss: 0.4301 - val_acc: 0.7907\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.82946\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3939 - acc: 0.8444 - val_loss: 0.4233 - val_acc: 0.7868\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.82946\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3634 - acc: 0.8491 - val_loss: 0.3553 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.82946 to 0.83333, saving model to weights.data_aug.hdf5\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.4281 - acc: 0.8131 - val_loss: 0.4437 - val_acc: 0.8023\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.83333\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3722 - acc: 0.8455 - val_loss: 0.3532 - val_acc: 0.8450\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.83333 to 0.84496, saving model to weights.data_aug.hdf5\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.3262 - acc: 0.8721 - val_loss: 0.3566 - val_acc: 0.8488\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.84496 to 0.84884, saving model to weights.data_aug.hdf5\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.3780 - acc: 0.8387 - val_loss: 0.3414 - val_acc: 0.8488\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.84884\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3709 - acc: 0.8425 - val_loss: 0.3292 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.84884 to 0.86434, saving model to weights.data_aug.hdf5\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.4048 - acc: 0.8378 - val_loss: 0.3307 - val_acc: 0.8566\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.86434\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3322 - acc: 0.8683 - val_loss: 0.3381 - val_acc: 0.8450\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.86434\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3580 - acc: 0.8578 - val_loss: 0.4209 - val_acc: 0.8178\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.86434\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3588 - acc: 0.8546 - val_loss: 0.4220 - val_acc: 0.8217\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.86434\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3983 - acc: 0.8368 - val_loss: 0.5712 - val_acc: 0.7132\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.86434\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3572 - acc: 0.8550 - val_loss: 0.3217 - val_acc: 0.8566\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.86434\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3363 - acc: 0.8702 - val_loss: 0.3758 - val_acc: 0.8411\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.86434\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3260 - acc: 0.8738 - val_loss: 0.3143 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.86434\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3091 - acc: 0.8787 - val_loss: 0.3577 - val_acc: 0.8411\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.86434\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3528 - acc: 0.8567 - val_loss: 0.3251 - val_acc: 0.8527\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.86434\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3394 - acc: 0.8641 - val_loss: 0.3502 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.86434\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3127 - acc: 0.8787 - val_loss: 0.3292 - val_acc: 0.8527\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.86434\n",
      "Epoch 63/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3831 - acc: 0.8376 - val_loss: 0.4120 - val_acc: 0.8062\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.86434\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3208 - acc: 0.8747 - val_loss: 0.3046 - val_acc: 0.8837\n",
      "\n",
      "Epoch 00064: val_acc improved from 0.86434 to 0.88372, saving model to weights.data_aug.hdf5\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.3730 - acc: 0.8596 - val_loss: 0.3374 - val_acc: 0.8527\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.88372\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3022 - acc: 0.8783 - val_loss: 0.3024 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.88372\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3396 - acc: 0.8635 - val_loss: 0.5719 - val_acc: 0.7171\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.88372\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3037 - acc: 0.8787 - val_loss: 0.2992 - val_acc: 0.8760\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.88372\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.4363 - acc: 0.8649 - val_loss: 0.3466 - val_acc: 0.8411\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.88372\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.3011 - acc: 0.8834 - val_loss: 0.3698 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.88372\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3092 - acc: 0.8844 - val_loss: 0.4325 - val_acc: 0.8101\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.88372\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.2993 - acc: 0.8796 - val_loss: 0.4094 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.88372\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3034 - acc: 0.8740 - val_loss: 0.7412 - val_acc: 0.7364\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.88372\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3125 - acc: 0.8749 - val_loss: 0.5025 - val_acc: 0.7713\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.88372\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3183 - acc: 0.8692 - val_loss: 0.2923 - val_acc: 0.8798\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.88372\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3721 - acc: 0.8482 - val_loss: 0.4064 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.88372\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3131 - acc: 0.8757 - val_loss: 0.3284 - val_acc: 0.8488\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.88372\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3459 - acc: 0.8669 - val_loss: 0.3205 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.88372\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.2788 - acc: 0.8956 - val_loss: 0.3038 - val_acc: 0.8643\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.88372\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.3129 - acc: 0.8759 - val_loss: 0.4037 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.88372\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.3851 - acc: 0.8539 - val_loss: 0.3979 - val_acc: 0.8256\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.88372\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.2806 - acc: 0.8804 - val_loss: 0.3378 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.88372\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.2797 - acc: 0.8929 - val_loss: 0.3070 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.88372\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.2772 - acc: 0.8891 - val_loss: 0.2763 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.88372 to 0.89147, saving model to weights.data_aug.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "33/33 [==============================] - 1s 40ms/step - loss: 0.2674 - acc: 0.9005 - val_loss: 0.2958 - val_acc: 0.8760\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.89147\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.2926 - acc: 0.8882 - val_loss: 0.2718 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.89147 to 0.89922, saving model to weights.data_aug.hdf5\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.2504 - acc: 0.904 - 1s 44ms/step - loss: 0.2611 - acc: 0.8958 - val_loss: 0.3855 - val_acc: 0.8411\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.89922\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 1s 43ms/step - loss: 0.3412 - acc: 0.8721 - val_loss: 0.3455 - val_acc: 0.8488\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.89922\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.2539 - acc: 0.9024 - val_loss: 0.2995 - val_acc: 0.8760\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.89922\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.2413 - acc: 0.9003 - val_loss: 0.3450 - val_acc: 0.8372\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.89922\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.2462 - acc: 0.9062 - val_loss: 0.3287 - val_acc: 0.8760\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.89922\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.2678 - acc: 0.8821 - val_loss: 0.2694 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.89922\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.2717 - acc: 0.8967 - val_loss: 0.2908 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.89922\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 1s 42ms/step - loss: 0.2390 - acc: 0.8994 - val_loss: 0.2764 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.89922\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 1s 41ms/step - loss: 0.2636 - acc: 0.8948 - val_loss: 0.2768 - val_acc: 0.9031\n",
      "\n",
      "Epoch 00095: val_acc improved from 0.89922 to 0.90310, saving model to weights.data_aug.hdf5\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 1s 42ms/step - loss: 0.2305 - acc: 0.9062 - val_loss: 0.6743 - val_acc: 0.7946\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.90310\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 1s 43ms/step - loss: 0.3061 - acc: 0.8702 - val_loss: 0.2724 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.90310\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 1s 44ms/step - loss: 0.2863 - acc: 0.8812 - val_loss: 0.3827 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.90310\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 1s 43ms/step - loss: 0.2475 - acc: 0.9100 - val_loss: 0.3075 - val_acc: 0.8876\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.90310\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 2s 46ms/step - loss: 0.2381 - acc: 0.9003 - val_loss: 0.3407 - val_acc: 0.8605\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.90310\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_43 (Conv2D)           (None, 50, 50, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 22, 22, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 11, 11, 256)       147712    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 9, 9, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 5,000,738\n",
      "Trainable params: 5,000,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Keras CNN 1 - accuracy: 0.8604651162790697 \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      IDC(-)       0.96      0.77      0.86       139\n",
      "      IDC(+)       0.78      0.97      0.86       119\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       258\n",
      "   macro avg       0.87      0.87      0.86       258\n",
      "weighted avg       0.88      0.86      0.86       258\n",
      "\n",
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# charger des images formes (5547, 50, 50, 3)\n",
    "X = np.load('D:/test cancer rbreast/crop/zoom_100m.npy')  \n",
    "\n",
    "# charger des images  (5547,1); (0 = no cancer, 1 = cancer)\n",
    "Y = np.load('D:/test cancer rbreast/crop/zoom_100m_label.npy')   \n",
    "perm_array = np.arange(len(X))\n",
    "#arrange genere tous toute les val jusqua la longuer de x_images\n",
    "np.random.shuffle(perm_array)\n",
    "#il melange les images\n",
    "X = X[perm_array]\n",
    "Y = Y[perm_array]\n",
    "#en split notre dataset 80 % 20 %\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "# en redduit la taille de l'echantillon au cas ou en avais trop d'images \n",
    "#pour pas que ca prend trop de temps pour le pc \n",
    "#mais ici c'est pas le cas donc en commente ce code\n",
    "#X_train = X_train[0:30000] \n",
    "#Y_train = Y_train[0:30000]\n",
    "#X_test = X_test[0:30000] \n",
    "#Y_test = Y_test[0:30000]\n",
    "\n",
    "# normalizer nos donnees \n",
    "#en pourrais utiliser d'autre methodes aussi mais celle la c'est bien \n",
    "X_train = X_train / 256.0\n",
    "X_test = X_test / 256.0\n",
    "#methode qu'on a trouver sur internet et qu'on a utiliser \n",
    "X_trainShape = X_train.shape[1]*X_train.shape[2]*X_train.shape[3]\n",
    "X_testShape = X_test.shape[1]*X_test.shape[2]*X_test.shape[3]\n",
    "#en applatit les donnees en gros en les transfrome en une matrice 1 seul dimmenssion nbr elem*(width*height*channel)\n",
    "X_trainFlat = X_train.reshape(X_train.shape[0], X_trainShape)\n",
    "X_testFlat = X_test.reshape(X_test.shape[0], X_testShape)\n",
    "Y_train = to_categorical(Y_train, num_classes = 2)\n",
    "Y_test = to_categorical(Y_test, num_classes = 2)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "#simple model\n",
    "def plotKerasLearningCurve():\n",
    "    #en affiche juste la courbe de notre model\n",
    "    plt.figure(figsize=(10,5))\n",
    "    metrics = np.load('logs.npy')[()]\n",
    "    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n",
    "    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n",
    "        l = np.array(metrics[k])\n",
    "        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n",
    "        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n",
    "        y = l[x]\n",
    "        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n",
    "        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n",
    "    plt.legend(loc=4)\n",
    "    plt.axis([0, None, None, None]);\n",
    "    plt.grid()\n",
    "    plt.xlabel('nombre d epoques')\n",
    "\n",
    "def runKerasCNN(a,b,c,d):\n",
    "    \"\"\"\n",
    "    en a utiliser ce lien\n",
    "    https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\n",
    "    en a utilise run model qui marche bien sur MNIST sur notre dataset\n",
    "    \"\"\"\n",
    "    batch_size = 128\n",
    "    num_classes = 2\n",
    "    epochs = 100 \n",
    "    img_rows, img_cols = X_train.shape[1],X_train.shape[2]\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "    x_train = a\n",
    "    y_train = b\n",
    "    x_test = c\n",
    "    y_test = d   \n",
    "    model = Sequential()\n",
    "    #test d'un premier model\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu', input_shape = input_shape))\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(Conv2D(filters = 86, kernel_size = (3,3),padding = 'Same', \n",
    "                     activation ='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation = \"softmax\"))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    datagen.fit(a)\n",
    "     # checkpoint\n",
    "    filepath=\"weights.data_aug.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    history =model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
    "              verbose=1,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),callbacks=callbacks_list)\n",
    "    \n",
    "    model.summary()\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('\\nKeras CNN 1 - accuracy:', score[1],'\\n')\n",
    "    y_pred = model.predict(c) \n",
    "    map_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\n",
    "    print('\\n', sklearn.metrics.classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='')\n",
    "    Y_pred_classes = np.argmax(y_pred,axis = 1) \n",
    "    Y_true = np.argmax(Y_test,axis = 1) \n",
    "    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "    print(history.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    plot_confusion_matrix(confusion_mtx, classes = list(map_characters.values()))\n",
    "runKerasCNN(X_train, Y_train,  X_test, Y_test)\n",
    "#plotKerasLearningCurve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
